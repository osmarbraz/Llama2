{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osmarbraz/exemplos_Llama2/blob/main/ExemplosGeracaoTexto_Llama2_Langchain_HuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78HE8FLsKN9Q"
      },
      "source": [
        "#Exemplo de Geração de textos usando Llama v2.0 7B 8bit usando Langchain e Transformers by HuggingFace\n",
        "\n",
        "Exemplo de uso do modelo de linguagem grande Llama v2.0.\n",
        "- Análise da geração de textos\n",
        "- Prompts com textos emparelhados\n",
        "- Injentando padrões no prompt\n",
        "- Padrão Persona\n",
        "- Verificação cognitiva\n",
        "- Pensamento em cadeia\n",
        "- Refinamento de perguntas\n",
        "\n",
        "**Toda a execução ocorre no Google Colaboratory.**\n",
        "\n",
        "Pré-requisitos:\n",
        "- Lhama 2 não está acessível abertamente e requer solicitação  de acesso. Faça o cadastro no site do https://huggingface.co/join. Depois do login, gere um token de acesso no link https://huggingface.co/settings/tokens.\n",
        "- Configurar o notebook para usar GPU- Acesse o menu 'Ambiente de Execução -> Alterar o tipo do ambiente de execução -> Acelerador de hardware -> T4 GPU\n",
        "\n",
        "\n",
        "**Referências**\n",
        "https://medium.com/the-techlife/using-huggingface-openai-and-cohere-models-with-langchain-db57af14ac5b\n",
        "\n",
        "\n",
        "**Notebook de referência:**\n",
        "\n",
        "https://github.com/guardiaum/tutorial-sbbd2023/blob/main/Prompt_Engineering.ipynb\n",
        "\n",
        "\n",
        "**Lista dos modelos:**\n",
        "\n",
        "https://huggingface.co/models\n",
        "\n",
        "\n",
        "**Artigos referências:**\n",
        "\n",
        "https://dev.to/nithinibhandari1999/how-to-run-llama-2-on-your-local-computer-42g1\n",
        "\n",
        "\n",
        "**Link biblioteca Huggingface:**\n",
        "\n",
        "https://github.com/huggingface/transformers\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyxb5Px3p1-e"
      },
      "source": [
        "# 0 - Preparação do ambiente\n",
        "Preparação do ambiente para execução do exemplo."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data e hora de execução"
      ],
      "metadata": {
        "id": "Q_O5mNHKt2oW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Biblioteca de date\n",
        "from datetime import datetime\n",
        "\n",
        "data_e_hora_atuais = datetime.now()\n",
        "data_e_hora_em_texto = data_e_hora_atuais.strftime('%d/%m/%Y %H:%M:%S')\n",
        "\n",
        "print(data_e_hora_em_texto)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpNBAbS1t5Xu",
        "outputId": "838b8f5b-aa5d-4964-b4bd-666f5d96106f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/04/2024 21:22:08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAPVtRXQqDim"
      },
      "source": [
        "## Tratamento de logs\n",
        "\n",
        "Método para tratamento dos logs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcopxbGZqDip"
      },
      "outputs": [],
      "source": [
        "# Biblioteca de logging\n",
        "import logging\n",
        "\n",
        "# Formatando a mensagem de logging\n",
        "logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GjYtXcMnSAe"
      },
      "source": [
        "## Identificando o ambiente Colab\n",
        "\n",
        "Cria uma variável para identificar que o notebook está sendo executado no Google Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMiH0E3OnRa1"
      },
      "outputs": [],
      "source": [
        "# Biblioteca do sistema\n",
        "import sys\n",
        "\n",
        "# Retorna true ou false se estiver no Google Colaboratory\n",
        "IN_COLAB = \"google.colab\" in sys.modules"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Versão Python"
      ],
      "metadata": {
        "id": "B-xSroBtxPL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Biblioteca do sistema\n",
        "import sys\n",
        "\n",
        "print(\"Versão Python:\", sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xu2haQbxRTc",
        "outputId": "05f5b9db-66bf-4c4e-ed36-cdaab2277fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versão Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZrNxBGQdMrM"
      },
      "source": [
        "## GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0qbx-9EdMxS",
        "outputId": "66c16c00-3f0f-4fe7-8c4f-b8b8f897ad9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU está disponível.\n"
          ]
        }
      ],
      "source": [
        "# Import de biblioteca\n",
        "import torch\n",
        "\n",
        "GPU_ENABLE = torch.cuda.is_available()\n",
        "\n",
        "if GPU_ENABLE:\n",
        "    print(\"GPU está disponível.\")\n",
        "else:\n",
        "    print(\"GPU não está disponível.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKmhxcvIfbG2"
      },
      "source": [
        "## Funções auxiliares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "603LYIYKBmq5"
      },
      "source": [
        "Função auxiliar para formatar o tempo como `hh: mm: ss`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Guy6B4whsZFR"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas.\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def formataTempo(tempo):\n",
        "    \"\"\"\n",
        "      Pega a tempo em segundos e retorna uma string hh:mm:ss\n",
        "    \"\"\"\n",
        "    # Arredonda para o segundo mais próximo.\n",
        "    tempo_arredondado = int(round((tempo)))\n",
        "\n",
        "    # Formata como hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=tempo_arredondado))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1vu-ch8yT5R"
      },
      "source": [
        "Imprime linhas menores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BKQZtF9yUBs"
      },
      "outputs": [],
      "source": [
        "def print_linhas_menores(texto, tamanho=120):\n",
        "  for i in range(0, len(texto), tamanho):\n",
        "    print(texto[i:i+tamanho])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqa-7WXBAw8q"
      },
      "source": [
        "# 1 - Instalação das bibliotecas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGrlTKgSLdNj"
      },
      "source": [
        "Bibioteca LangChain é um framework de código aberto para o desenvolvimento de aplicações usando modelos de linguagem grandes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppVeArJcLdVb",
        "outputId": "5ce9595d-8968-4da7-ff24-d5c5a2498d38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.1.16\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.16)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.1.16)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.32 (from langchain==0.1.16)\n",
            "  Downloading langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.42 (from langchain==0.1.16)\n",
            "  Downloading langchain_core-0.1.45-py3-none-any.whl (291 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.3/291.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.16)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.16)\n",
            "  Downloading langsmith-0.1.50-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (2.7.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.16) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.16) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.16)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.1.16)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain==0.1.16)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.1.16)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.16) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.16) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.16) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.16)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.16 langchain-community-0.0.34 langchain-core-0.1.45 langchain-text-splitters-0.0.1 langsmith-0.1.50 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.1 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.1.16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp0jVfo3QM3h"
      },
      "source": [
        "O bitsandbytes é um wrapper leve em torno de funções personalizadas CUDA, em particular otimizadores de 8 bits, multiplicação de matrizes (LLM.int8()) e funções de quantização. É uma dependência do accelerate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12GE2W3fQM_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "337d8e71-4047-4e79-805a-6053a42975c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes==0.43.1\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.43.1) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.43.1) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->bitsandbytes==0.43.1)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->bitsandbytes==0.43.1)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->bitsandbytes==0.43.1)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->bitsandbytes==0.43.1)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->bitsandbytes==0.43.1)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->bitsandbytes==0.43.1)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->bitsandbytes==0.43.1)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->bitsandbytes==0.43.1)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->bitsandbytes==0.43.1)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->bitsandbytes==0.43.1)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->bitsandbytes==0.43.1)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.1) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes==0.43.1)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes==0.43.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes==0.43.1) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install bitsandbytes==0.43.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7wU6vuyAuPd"
      },
      "source": [
        "Accelerate é uma biblioteca que permite que o mesmo código PyTorch seja executado em qualquer configuração distribuída adicionando apenas quatro linhas de código. Otimiza as operações do PyTorch, especialmente na GPU.\n",
        "\n",
        "https://pypi.org/project/accelerate/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTMID1rZAvx7",
        "outputId": "83435382-9a57-4f38-e03d-607ea169c7b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate==0.29.3\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/297.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m297.0/297.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.3) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.3) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.3) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.3) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.3) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.3) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.29.3) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.29.3) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.29.3) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.29.3) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.29.3) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.29.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.29.3) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.29.3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.29.3) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.29.3\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate==0.29.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCdqJCtQN52l"
      },
      "source": [
        "A Biblioteca A Biblioteca Transformers fornece APIs e ferramentas para baixar e treinar facilmente modelos pré-treinados de última geração para Processamento de linguagem natural, Visão computacional, Áudio, etc.\n",
        "\n",
        "Fornece uma maneira direta de usar modelos pré-treinados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RfUN_KolV-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d4be54-f2c0-4b54-84df-dc35cf163903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.40.0 in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.40.0) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.40.0) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers==4.40.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlrWrRP02tuZ"
      },
      "source": [
        "A Biblioteca huggingface-cli fornece vários comandos para interagir com o Hugging Face Hub a partir da linha de comando. Um desses comandos é o login, que permite aos usuários se autenticarem no Hub usando suas credenciais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQxtD3Zk14ov"
      },
      "outputs": [],
      "source": [
        "#!pip install huggingface-hub==0.20.3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Versão bibliotecas instaladas"
      ],
      "metadata": {
        "id": "9NdUAv1OyE7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffCAEnsNyG4G",
        "outputId": "6db48320-881c-4d9f-cc49-64555230e350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.4.0\n",
            "accelerate==0.29.3\n",
            "aiohttp==3.9.5\n",
            "aiosignal==1.3.1\n",
            "alabaster==0.7.16\n",
            "albumentations==1.3.1\n",
            "altair==4.2.2\n",
            "annotated-types==0.6.0\n",
            "anyio==3.7.1\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==23.1.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array_record==0.5.1\n",
            "arviz==0.15.1\n",
            "astropy==5.3.4\n",
            "astunparse==1.6.3\n",
            "async-timeout==4.0.3\n",
            "atpublic==4.1.0\n",
            "attrs==23.2.0\n",
            "audioread==3.0.1\n",
            "autograd==1.6.2\n",
            "Babel==2.14.0\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.12.3\n",
            "bidict==0.23.1\n",
            "bigframes==1.2.0\n",
            "bitsandbytes==0.43.1\n",
            "bleach==6.1.0\n",
            "blinker==1.4\n",
            "blis==0.7.11\n",
            "blosc2==2.0.0\n",
            "bokeh==3.3.4\n",
            "bqplot==0.12.43\n",
            "branca==0.7.1\n",
            "build==1.2.1\n",
            "CacheControl==0.14.0\n",
            "cachetools==5.3.3\n",
            "catalogue==2.0.10\n",
            "certifi==2024.2.2\n",
            "cffi==1.16.0\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.3.2\n",
            "chex==0.1.86\n",
            "click==8.1.7\n",
            "click-plugins==1.1.1\n",
            "cligj==0.7.2\n",
            "cloudpathlib==0.16.0\n",
            "cloudpickle==2.2.1\n",
            "cmake==3.27.9\n",
            "cmdstanpy==1.2.2\n",
            "colorcet==3.1.0\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.4\n",
            "cons==0.4.6\n",
            "contextlib2==21.6.0\n",
            "contourpy==1.2.1\n",
            "cryptography==42.0.5\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda12x==12.2.0\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.3.3\n",
            "cycler==0.12.1\n",
            "cymem==2.0.8\n",
            "Cython==3.0.10\n",
            "dask==2023.8.1\n",
            "dataclasses-json==0.6.4\n",
            "datascience==0.17.6\n",
            "db-dtypes==1.2.0\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.6.6\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "distributed==2023.8.1\n",
            "distro==1.7.0\n",
            "dlib==19.24.4\n",
            "dm-tree==0.1.8\n",
            "docstring_parser==0.16\n",
            "docutils==0.18.1\n",
            "dopamine-rl==4.0.6\n",
            "duckdb==0.10.2\n",
            "earthengine-api==0.1.399\n",
            "easydict==1.13\n",
            "ecos==2.0.13\n",
            "editdistance==0.6.2\n",
            "eerepr==0.0.4\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\n",
            "entrypoints==0.4\n",
            "et-xmlfile==1.1.0\n",
            "etils==1.7.0\n",
            "etuples==0.3.9\n",
            "exceptiongroup==1.2.1\n",
            "fastai==2.7.14\n",
            "fastcore==1.5.29\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.19.1\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.2\n",
            "filelock==3.13.4\n",
            "fiona==1.9.6\n",
            "firebase-admin==5.3.0\n",
            "Flask==2.2.5\n",
            "flatbuffers==24.3.25\n",
            "flax==0.8.2\n",
            "folium==0.14.0\n",
            "fonttools==4.51.0\n",
            "frozendict==2.4.2\n",
            "frozenlist==1.4.1\n",
            "fsspec==2023.6.0\n",
            "future==0.18.3\n",
            "gast==0.5.4\n",
            "gcsfs==2023.6.0\n",
            "GDAL==3.6.4\n",
            "gdown==5.1.0\n",
            "geemap==0.32.0\n",
            "gensim==4.3.2\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.0\n",
            "geopandas==0.13.2\n",
            "geopy==2.3.0\n",
            "gin-config==0.5.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-ai-generativelanguage==0.4.0\n",
            "google-api-core==2.11.1\n",
            "google-api-python-client==2.84.0\n",
            "google-auth==2.27.0\n",
            "google-auth-httplib2==0.1.1\n",
            "google-auth-oauthlib==1.2.0\n",
            "google-cloud-aiplatform==1.48.0\n",
            "google-cloud-bigquery==3.12.0\n",
            "google-cloud-bigquery-connection==1.12.1\n",
            "google-cloud-bigquery-storage==2.24.0\n",
            "google-cloud-core==2.3.3\n",
            "google-cloud-datastore==2.15.2\n",
            "google-cloud-firestore==2.11.1\n",
            "google-cloud-functions==1.13.3\n",
            "google-cloud-iam==2.15.0\n",
            "google-cloud-language==2.13.3\n",
            "google-cloud-resource-manager==1.12.3\n",
            "google-cloud-storage==2.8.0\n",
            "google-cloud-translate==3.11.3\n",
            "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz#sha256=d995c645ccb6cd9951858edc8c5feb9eab7b5ce8c495596e7e471227b2c667da\n",
            "google-crc32c==1.5.0\n",
            "google-generativeai==0.3.2\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.7.0\n",
            "googleapis-common-protos==1.63.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.20.3\n",
            "greenlet==3.0.3\n",
            "grpc-google-iam-v1==0.13.0\n",
            "grpcio==1.62.2\n",
            "grpcio-status==1.48.2\n",
            "gspread==3.4.2\n",
            "gspread-dataframe==3.3.1\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "h5netcdf==1.3.0\n",
            "h5py==3.9.0\n",
            "holidays==0.47\n",
            "holoviews==1.17.1\n",
            "html5lib==1.1\n",
            "httpimport==1.3.1\n",
            "httplib2==0.22.0\n",
            "huggingface-hub==0.20.3\n",
            "humanize==4.7.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==8.0.0\n",
            "idna==3.7\n",
            "imageio==2.31.6\n",
            "imageio-ffmpeg==0.4.9\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.10.1\n",
            "imgaug==0.4.0\n",
            "importlib_metadata==7.1.0\n",
            "importlib_resources==6.4.0\n",
            "imutils==0.5.4\n",
            "inflect==7.0.0\n",
            "iniconfig==2.0.0\n",
            "intel-openmp==2023.2.4\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==5.5.6\n",
            "ipyleaflet==0.18.2\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.2.0\n",
            "jax==0.4.26\n",
            "jaxlib @ https://storage.googleapis.com/jax-releases/cuda12/jaxlib-0.4.26+cuda12.cudnn89-cp310-cp310-manylinux2014_x86_64.whl#sha256=813cf1fe3e7ca4dbf5327d6e7b4fc8521e92d8bba073ee645ae0d5d036a25750\n",
            "jeepney==0.7.1\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.3\n",
            "joblib==1.4.0\n",
            "jsonpatch==1.33\n",
            "jsonpickle==3.0.4\n",
            "jsonpointer==2.4\n",
            "jsonschema==4.19.2\n",
            "jsonschema-specifications==2023.12.1\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.7.2\n",
            "jupyterlab_pygments==0.3.0\n",
            "jupyterlab_widgets==3.0.10\n",
            "kaggle==1.5.16\n",
            "kagglehub==0.2.3\n",
            "keras==2.15.0\n",
            "keyring==23.5.0\n",
            "kiwisolver==1.4.5\n",
            "langchain==0.1.16\n",
            "langchain-community==0.0.34\n",
            "langchain-core==0.1.45\n",
            "langchain-text-splitters==0.0.1\n",
            "langcodes==3.3.0\n",
            "langsmith==0.1.50\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.4\n",
            "libclang==18.1.1\n",
            "librosa==0.10.1\n",
            "lightgbm==4.1.0\n",
            "linkify-it-py==2.0.3\n",
            "llvmlite==0.41.1\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==4.9.4\n",
            "malloy==2023.1067\n",
            "Markdown==3.6\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==2.1.5\n",
            "marshmallow==3.21.1\n",
            "matplotlib==3.7.1\n",
            "matplotlib-inline==0.1.7\n",
            "matplotlib-venn==0.11.10\n",
            "mdit-py-plugins==0.4.0\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==0.8.4\n",
            "mizani==0.9.3\n",
            "mkl==2023.2.0\n",
            "ml-dtypes==0.2.0\n",
            "mlxtend==0.22.0\n",
            "more-itertools==10.1.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.0.8\n",
            "multidict==6.0.5\n",
            "multipledispatch==1.0.0\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.10\n",
            "music21==9.1.0\n",
            "mypy-extensions==1.0.0\n",
            "natsort==8.4.0\n",
            "nbclassic==1.0.0\n",
            "nbclient==0.10.0\n",
            "nbconvert==6.5.4\n",
            "nbformat==5.10.4\n",
            "nest-asyncio==1.6.0\n",
            "networkx==3.3\n",
            "nibabel==4.0.2\n",
            "nltk==3.8.1\n",
            "notebook==6.5.5\n",
            "notebook_shim==0.2.4\n",
            "numba==0.58.1\n",
            "numexpr==2.10.0\n",
            "numpy==1.25.2\n",
            "nvidia-cublas-cu12==12.1.3.1\n",
            "nvidia-cuda-cupti-cu12==12.1.105\n",
            "nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "nvidia-cuda-runtime-cu12==12.1.105\n",
            "nvidia-cudnn-cu12==8.9.2.26\n",
            "nvidia-cufft-cu12==11.0.2.54\n",
            "nvidia-curand-cu12==10.3.2.106\n",
            "nvidia-cusolver-cu12==11.4.5.107\n",
            "nvidia-cusparse-cu12==12.1.0.106\n",
            "nvidia-nccl-cu12==2.19.3\n",
            "nvidia-nvjitlink-cu12==12.4.127\n",
            "nvidia-nvtx-cu12==12.1.105\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "opencv-contrib-python==4.8.0.76\n",
            "opencv-python==4.8.0.76\n",
            "opencv-python-headless==4.9.0.80\n",
            "openpyxl==3.1.2\n",
            "opt-einsum==3.3.0\n",
            "optax==0.2.2\n",
            "orbax-checkpoint==0.4.4\n",
            "orjson==3.10.1\n",
            "osqp==0.6.2.post8\n",
            "packaging==23.2\n",
            "pandas==2.0.3\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.19.2\n",
            "pandas-stubs==2.0.3.230814\n",
            "pandocfilters==1.5.1\n",
            "panel==1.3.8\n",
            "param==2.1.0\n",
            "parso==0.8.4\n",
            "parsy==2.1\n",
            "partd==1.4.1\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.6\n",
            "peewee==3.17.3\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==9.4.0\n",
            "pip-tools==6.13.0\n",
            "platformdirs==4.2.0\n",
            "plotly==5.15.0\n",
            "plotnine==0.12.4\n",
            "pluggy==1.4.0\n",
            "polars==0.20.2\n",
            "pooch==1.8.1\n",
            "portpicker==1.5.2\n",
            "prefetch-generator==1.0.3\n",
            "preshed==3.0.9\n",
            "prettytable==3.10.0\n",
            "proglog==0.1.10\n",
            "progressbar2==4.2.0\n",
            "prometheus_client==0.20.0\n",
            "promise==2.3\n",
            "prompt-toolkit==3.0.43\n",
            "prophet==1.1.5\n",
            "proto-plus==1.23.0\n",
            "protobuf==3.20.3\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.9\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==14.0.2\n",
            "pyarrow-hotfix==0.6\n",
            "pyasn1==0.6.0\n",
            "pyasn1_modules==0.4.0\n",
            "pycocotools==2.0.7\n",
            "pycparser==2.22\n",
            "pydantic==2.7.0\n",
            "pydantic_core==2.18.1\n",
            "pydata-google-auth==1.8.2\n",
            "pydot==1.4.2\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "PyDrive2==1.6.3\n",
            "pyerfa==2.0.1.4\n",
            "pygame==2.5.2\n",
            "Pygments==2.16.1\n",
            "PyGObject==3.42.1\n",
            "PyJWT==2.3.0\n",
            "pymc==5.10.4\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.7\n",
            "pyOpenSSL==24.1.0\n",
            "pyparsing==3.1.2\n",
            "pyperclip==1.8.2\n",
            "pyproj==3.6.1\n",
            "pyproject_hooks==1.0.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pytensor==2.18.6\n",
            "pytest==7.4.4\n",
            "python-apt @ file:///backend-container/containers/python_apt-0.0.0-cp310-cp310-linux_x86_64.whl#sha256=b209c7165d6061963abe611492f8c91c3bcef4b7a6600f966bab58900c63fefa\n",
            "python-box==7.1.1\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.4\n",
            "python-utils==3.8.2\n",
            "pytz==2023.4\n",
            "pyviz_comms==3.0.2\n",
            "PyWavelets==1.6.0\n",
            "PyYAML==6.0.1\n",
            "pyzmq==23.2.1\n",
            "qdldl==0.1.7.post2\n",
            "qudida==0.0.4\n",
            "ratelim==0.1.6\n",
            "referencing==0.34.0\n",
            "regex==2023.12.25\n",
            "requests==2.31.0\n",
            "requests-oauthlib==1.3.1\n",
            "requirements-parser==0.9.0\n",
            "rich==13.7.1\n",
            "rpds-py==0.18.0\n",
            "rpy2==3.4.2\n",
            "rsa==4.9\n",
            "safetensors==0.4.3\n",
            "scikit-image==0.19.3\n",
            "scikit-learn==1.2.2\n",
            "scipy==1.11.4\n",
            "scooby==0.9.2\n",
            "scs==3.2.4.post1\n",
            "seaborn==0.13.1\n",
            "SecretStorage==3.3.1\n",
            "Send2Trash==1.8.3\n",
            "sentencepiece==0.1.99\n",
            "shapely==2.0.4\n",
            "six==1.16.0\n",
            "sklearn-pandas==2.2.0\n",
            "smart-open==6.4.0\n",
            "sniffio==1.3.1\n",
            "snowballstemmer==2.2.0\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.12.1\n",
            "soupsieve==2.5\n",
            "soxr==0.3.7\n",
            "spacy==3.7.4\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "Sphinx==5.0.2\n",
            "sphinxcontrib-applehelp==1.0.8\n",
            "sphinxcontrib-devhelp==1.0.6\n",
            "sphinxcontrib-htmlhelp==2.0.5\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==1.0.7\n",
            "sphinxcontrib-serializinghtml==1.1.10\n",
            "SQLAlchemy==2.0.29\n",
            "sqlglot==20.11.0\n",
            "sqlparse==0.5.0\n",
            "srsly==2.4.8\n",
            "stanio==0.5.0\n",
            "statsmodels==0.14.2\n",
            "sympy==1.12\n",
            "tables==3.8.0\n",
            "tabulate==0.9.0\n",
            "tbb==2021.12.0\n",
            "tblib==3.0.0\n",
            "tenacity==8.2.3\n",
            "tensorboard==2.15.2\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow @ https://storage.googleapis.com/colab-tf-builds-public-09h6ksrfwbb9g9xv/tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=a2ec79931350b378c1ef300ca836b52a55751acb71a433582508a07f0de57c42\n",
            "tensorflow-datasets==4.9.4\n",
            "tensorflow-estimator==2.15.0\n",
            "tensorflow-gcs-config==2.15.0\n",
            "tensorflow-hub==0.16.1\n",
            "tensorflow-io-gcs-filesystem==0.36.0\n",
            "tensorflow-metadata==1.14.0\n",
            "tensorflow-probability==0.23.0\n",
            "tensorstore==0.1.45\n",
            "termcolor==2.4.0\n",
            "terminado==0.18.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.17.1\n",
            "tf-slim==1.1.0\n",
            "tf_keras==2.15.1\n",
            "thinc==8.2.3\n",
            "threadpoolctl==3.4.0\n",
            "tifffile==2024.4.18\n",
            "tinycss2==1.2.1\n",
            "tokenizers==0.19.1\n",
            "toml==0.10.2\n",
            "tomli==2.0.1\n",
            "toolz==0.12.1\n",
            "torch @ https://download.pytorch.org/whl/cu121/torch-2.2.1%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=1adf430f01ff649c848ac021785e18007b0714fdde68e4e65bd0c640bf3fb8e1\n",
            "torchaudio @ https://download.pytorch.org/whl/cu121/torchaudio-2.2.1%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=23f6236429e2bf676b820e8e7221a1d58aaf908bff2ba2665aa852df71a97961\n",
            "torchdata==0.7.1\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.17.1\n",
            "torchvision @ https://download.pytorch.org/whl/cu121/torchvision-0.17.1%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=27af47915f6e762c1d44e58e8088d22ac97445668f9f793524032b2baf4f34bd\n",
            "tornado==6.3.3\n",
            "tqdm==4.66.2\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "transformers==4.40.0\n",
            "triton==2.2.0\n",
            "tweepy==4.14.0\n",
            "typer==0.9.4\n",
            "types-pytz==2024.1.0.20240417\n",
            "types-setuptools==69.5.0.20240423\n",
            "typing-inspect==0.9.0\n",
            "typing_extensions==4.11.0\n",
            "tzdata==2024.1\n",
            "tzlocal==5.2\n",
            "uc-micro-py==1.0.3\n",
            "uritemplate==4.1.1\n",
            "urllib3==2.0.7\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wasabi==1.1.2\n",
            "wcwidth==0.2.13\n",
            "weasel==0.3.4\n",
            "webcolors==1.13\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.7.0\n",
            "Werkzeug==3.0.2\n",
            "widgetsnbextension==3.6.6\n",
            "wordcloud==1.9.3\n",
            "wrapt==1.14.1\n",
            "xarray==2023.7.0\n",
            "xarray-einstats==0.7.0\n",
            "xgboost==2.0.3\n",
            "xlrd==2.0.1\n",
            "xyzservices==2024.4.0\n",
            "yarl==1.9.4\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.38\n",
            "zict==3.0.0\n",
            "zipp==3.18.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcpd9t9PpkrX"
      },
      "source": [
        "# 2 - Carregando o LLM\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFRSYoCArrQ-"
      },
      "source": [
        "## 2.1 - Login no huggingface\n",
        "\n",
        "- Lhama 2 não está acessível abertamente e requer solicitação  de acesso. Faça o cadastro no site do https://huggingface.co/join. Depois do login, gere um token de acesso no link https://huggingface.co/settings/tokens.\n",
        "\n",
        "Insira o token quando solicitado e depois digite Y para adicionar as credenciais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bkqIoNU18UH"
      },
      "outputs": [],
      "source": [
        "# !huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACJuj9wB9kjZ"
      },
      "source": [
        "Se o seu notebook não for público e não desejar incluir o token de acesso toda vez que for executar o notebook preencha o método save_token.\n",
        "\n",
        "\n",
        "Crie a variável 'HF_TOKEN' com o valor do **Access Token do HuggingFace**. Abra o Google Colab e navegue até a nova seção 'Secrets' na barra lateral e adicione a variável."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRVr7uqp9Ubk"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub.hf_api import HfFolder\n",
        "\n",
        "if IN_COLAB:\n",
        "\n",
        "    from google.colab import userdata\n",
        "\n",
        "    # ACESS_TOKEN = \"<valor_do_acess_token\"\n",
        "    ACCESS_TOKEN  = userdata.get('HF_TOKEN')\n",
        "\n",
        "    HfFolder.save_token(ACCESS_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIzrrJLw9oQd"
      },
      "source": [
        "Mostrando o usuário conectado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLrSstlxR_kq"
      },
      "outputs": [],
      "source": [
        "# !huggingface-cli whoami"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niwUEmYM6kjG"
      },
      "source": [
        "## 2.2 - Nome do modelo de linguagem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBOzL86X6kjM"
      },
      "source": [
        "Define o nome do modelo a ser carregado\n",
        "Lista dos modelos:\n",
        "  - https://huggingface.co/meta-llama/Llama-2-7b-hf\n",
        "  - https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\n",
        "  - https://huggingface.co/meta-llama/Llama-2-13b-hf\n",
        "  - https://huggingface.co/meta-llama/Llama-2-13b-chat-hf\n",
        "  - https://huggingface.co/meta-llama/Llama-2-70b-hf\n",
        "  - https://huggingface.co/meta-llama/Llama-2-70b-chat-hf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zOnSymM6kjM"
      },
      "outputs": [],
      "source": [
        "#nome_modelo = \"meta-llama/Llama-2-7b-hf\"\n",
        "nome_modelo = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "\n",
        "#nome_modelo = \"meta-llama/Llama-2-13b-hf\"\n",
        "# nome_modelo = \"meta-llama/Llama-2-13b-chat-hf\"\n",
        "\n",
        "# Não roda pois exige GPU A100 e mais espaço em disco\n",
        "#nome_modelo = \"meta-llama/Llama-2-70b-hf\"\n",
        "# nome_modelo = \"meta-llama/Llama-2-70b-chat-hf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzWcQNSORrYC"
      },
      "source": [
        "## 2.3 - Carrega o tokenizador\n",
        "\n",
        "Carregando o **tokenizador** da comunidade."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "21d072e029f741f8924386dc117b0698",
            "e85d39a6ae4d401389c447f9e9e720a2",
            "1532a6765aad441a97a37e1f61a1fb0b",
            "120227e3a4164d5c9d54562d0e95086c",
            "1e1af129a7c4401abd5aeccbeae0e2a4",
            "57e1c19033a74badadf9fa9ff2d899f7",
            "33fbce20a5ba49039052cf20d013238d",
            "bb54779e098d4dba9d74fa325eb949fa",
            "1a1374d61a9a400fb1ae637763c0c1e1",
            "b79f4316e39b4dd6b424f02b48094fcb",
            "11620c1357b144aea2139e023cbab147",
            "9d5af3edf3034bdbb08948c8d55e6b8b",
            "76ab48ae5e4946b8aac24786dda8af56",
            "9f55a673972740a98dc09ac600be5d68",
            "8ec59f0fcc81407bb6af298b5ac21730",
            "4ee24757394540cab53bd79675e0f7e8",
            "22391979a5e346b5a1c302835407f92c",
            "da3313cdd23649399f434cc8b188b60e",
            "d0913cc28c894f91a87d4cee34a1e3e2",
            "ad5714b6a2714c0bb190f26d1e007dfd",
            "5a8cee0e1d344ab2903b74d3ea1a7e41",
            "a670a9ada8b140dea5237f338f0085e0",
            "c38c85cd517d4dd799863201a8a568d5",
            "38b9d594146d4a4eb70df039a5e1a4ec",
            "484137fc476645c3a0a0fa8dc52ece80",
            "ade136a160704664bae77e1fe1675482",
            "75c31410d77a4a4ca6e29bb7562d7327",
            "03f4c7331a1a4176b99ee322bcc5bb63",
            "a1ee6c16861b406c8b32fdddb411740f",
            "e578eecd0cb5436184d19db998ddc989",
            "f94460300ee94240b192c41cc4681a50",
            "939074156fa0459b8834aa9aea2c5c63",
            "650ab0f1abf847de8c77c6c49789b2de",
            "5b117bb2aa084b69978b4d1f3eea068d",
            "3e7776766e754b02bfe2efe50ad13a64",
            "762ae65b750646849691accf6b305b7b",
            "049fffd112f8412fbacab7247987f870",
            "b0a32de1b9f145509967a37aaee341d7",
            "3abf98e538f44f0088e82434a08d0a25",
            "ffc277fd73be4cca9535d1f86dc874a3",
            "c6840325304f414081a8d48bb6c9769c",
            "252cd15bae0b4582b1a12989badf2b75",
            "fb94fe5a13d54485bb5177c0c2c2d0e4",
            "e1e5b8e35d824a76af114a1e47aa7d3e"
          ]
        },
        "id": "MlSM1VufRw5B",
        "outputId": "576d4c68-3087-47c2-d860-d3d6afeac62e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando o tokenizador meta-llama/Llama-2-7b-chat-hf da comunidade...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21d072e029f741f8924386dc117b0698"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d5af3edf3034bdbb08948c8d55e6b8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c38c85cd517d4dd799863201a8a568d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b117bb2aa084b69978b4d1f3eea068d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Importando as bibliotecas do Tokenizador\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Carregando o Tokenizador da comunidade\n",
        "print('Carregando o tokenizador ' + nome_modelo + ' da comunidade...')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(nome_modelo)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tamanho do vocabulário"
      ],
      "metadata": {
        "id": "pNhZxBfM0LEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tokenizer))"
      ],
      "metadata": {
        "id": "IzgbIOUI0LEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03358db3-826d-462c-f76f-cac48b6314be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhNMEhN9BHuc"
      },
      "source": [
        "## 2.4 - Carregando o LLM\n",
        "\n",
        "Carregando o **LLM** da comunidade HuggingFace.\n",
        "\n",
        "Parametrização do from_pretrained\n",
        "https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregamento LLama 2 com 4 bits"
      ],
      "metadata": {
        "id": "oj6_jlk35AUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Importando as bibliotecas do Modelo\n",
        "# from transformers import BitsAndBytesConfig, AutoModelForCausalLM\n",
        "# import torch\n",
        "# import time\n",
        "\n",
        "# # Guarda o tempo de início do carregamento do modelo\n",
        "# tempo_inicio = time.time()\n",
        "\n",
        "# # Carregando o Modelo da comunidade\n",
        "# print('Carregando o modelo ' + nome_modelo + ' da comunidade...')\n",
        "\n",
        "# # BitsAndBytes é um framework com funções customizadas para\n",
        "# # otimização com precisão 8-bit, multiplicações de matrizes e funções de quantização\n",
        "# quantization_config = BitsAndBytesConfig(\n",
        "#    load_in_4bit=True, # Habilita a quantização de 4 bits para comprimir o modelo\n",
        "#    bnb_4bit_quant_type=\"nf4\", # Define o tipo de dados de quantização nas camadas (`fp4` e `nf4`).\n",
        "#    bnb_4bit_use_double_quant=True, # Quantização aninhada, onde as constantes de quantização da primeira quantização são quantizadas novamente.\n",
        "#    bnb_4bit_compute_dtype=torch.bfloat16 # # Os gradientes dos pesos são computados em 16-bit. Define o tipo computacional que pode ser diferente do tempo de entrada. Por exemplo, as entradas podem ser fp32, mas a computação pode ser definida como bf16 para acelerações.\n",
        "# )\n",
        "\n",
        "# # Carrega o modelo\n",
        "# model = AutoModelForCausalLM.from_pretrained(nome_modelo,\n",
        "#                                              #torch_dtype=torch.float16, #default\n",
        "#                                              trust_remote_code=True, # Carrega de um repositório confiável\n",
        "#                                              quantization_config=quantization_config,\n",
        "#                                              device_map=\"auto\"\n",
        "#                                              )\n",
        "\n",
        "# # Coloca o modelo e modo avaliação\n",
        "# model.eval()\n",
        "\n",
        "# # Aumentar a velocidade\n",
        "# # https://huggingface.co/docs/transformers/main/perf_torch_compile\n",
        "# model = torch.compile(model)\n",
        "\n",
        "# print(\"Tempo de carregamento do modelo LLM:  {:} (h:mm:ss)\".format(formataTempo(time.time() - tempo_inicio)))"
      ],
      "metadata": {
        "id": "5Kx5Ed64YlV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregamento LLama 2 com 8 bits"
      ],
      "metadata": {
        "id": "doIqirI05Dos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas do Modelo\n",
        "from transformers import BitsAndBytesConfig, AutoModelForCausalLM\n",
        "import torch\n",
        "import time\n",
        "\n",
        "# Guarda o tempo de início do carregamento do modelo\n",
        "tempo_inicio = time.time()\n",
        "\n",
        "# Carregando o Modelo da comunidade\n",
        "print('Carregando o modelo ' + nome_modelo + ' da comunidade...')\n",
        "\n",
        "# BitsAndBytes é um framework com funções customizadas para\n",
        "# otimização com precisão 8-bit, multiplicações de matrizes e funções de quantização\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "   load_in_8bit=True, # Habilita a quantização de 8 bits\n",
        ")\n",
        "\n",
        "# Carrega o modelo\n",
        "model = AutoModelForCausalLM.from_pretrained(nome_modelo,\n",
        "                                             #torch_dtype=torch.float16, #default\n",
        "                                             trust_remote_code=True, # Carrega de um repositório confiável\n",
        "                                             quantization_config=quantization_config,\n",
        "                                             device_map=\"auto\"\n",
        "                                             )\n",
        "\n",
        "# Coloca o modelo e modo avaliação\n",
        "model.eval()\n",
        "\n",
        "# Aumentar a velocidade\n",
        "# https://huggingface.co/docs/transformers/main/perf_torch_compile\n",
        "model = torch.compile(model)\n",
        "\n",
        "print(\"Tempo de carregamento do modelo LLM:  {:} (h:mm:ss)\".format(formataTempo(time.time() - tempo_inicio)))"
      ],
      "metadata": {
        "id": "WTFnuVQ3R0gp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "43fbedfdd0104fa0bd8b809e3e9be296",
            "5af177c9f68448448f8c36427084385c",
            "1ee2b64e90f54d1bb7d38e480e81c743",
            "b90c28b165074241a5f8f64b27fb0ba8",
            "0ce11403c63e4093abac84ef55938293",
            "58702fffdfa64efcb1fd21b130dc5a06",
            "5d5338d429d64fb8b8fa724da5fe59a9",
            "4d7aa498c0974f8e81894b78fe469f43",
            "d1b5af67c00c4853825ff27aa0ad6fc8",
            "f8bbbcf9f774434fb710adebdf3d9dc5",
            "5dd80e70980e4f47ac5a0e90c90ed598",
            "5c16a28806ad4088ad497a5b9a232ccf",
            "4aa4c1202a864d38919ccc20e816213f",
            "279e524569a64f3693131df12db43849",
            "4b4c47a15f4c471fa918c60354d78759",
            "60695efe6a3d4145877213225de1312f",
            "1c3f9ffa853046b0828b88db1ffe673a",
            "d6888a26d7e348fab7bc284d82e46372",
            "7ed1522f17c540208d8fb00011abbfa4",
            "99fac7c968b146428c6d7892d22f2bd6",
            "e2008bf056b84715ab9c2d1db214db6b",
            "fa5c814b0d0949939eb2705a577ef207",
            "5b21adb73a7b4af2babe0d229af55abe",
            "787ad93a273d44bda844ac185ed64c33",
            "a5f849a733c6493f9795dcff3e8d38e5",
            "0111511dfb6d4682acb4270cf1e293ae",
            "02153c1d14734c9897f57bd3540bc0cc",
            "6e413f2bb7554b92a0462fae443a3809",
            "5a608ca8198e41ccb060ec13ce8f0d28",
            "a1c0a7c5b66041c2a9a47636065e130e",
            "a0319d13dc084a3dabe2409b8fef2c0a",
            "09bbf99815514948818179c1c92fda34",
            "64074fca3b364c86bb4e7a0f539c952b",
            "e57daad4217242b19b4fb8922470c942",
            "1ee96042dfe449699885119eb861d8af",
            "0bce14bd3cd94e23b112d331871b65e4",
            "4ff80581ed524d539057ef1af609fce9",
            "d557909aea3d49038a505b966c75419e",
            "aa8aa80f48654c82b37c5ab62bec35ab",
            "9f36a9a5720d4dae9e6e7a9d7e353c3c",
            "d60d7942e47c46f68b4169d3c08dddf0",
            "a60e3d7aef304e5d8dac372ffb0dfb68",
            "2d007edb5ae94801a4c5387867789ab6",
            "3009c92093334d48b26537ea46ad6596",
            "91cb92fdd39e4dc98b2b428c960a04d4",
            "d2ba398885c146799be1d18988156db1",
            "dc4de582cc004b6ea6be713cfb239899",
            "3ba95abbd8ec41639ef12320ed08a53d",
            "94da824f5bfb468cb515cb345462bc0d",
            "f727daf5a9a9484f8758323ddd1f4c1e",
            "a3df1a2269e74318b775d5b5282f5222",
            "fd6e0986a26a4d8784cf31088d58d427",
            "925376d4a0324bf7ab1585b3ac54622d",
            "a6e15e49bad04c369357eaff53bab230",
            "6edee10792af418a892e29ffd5579813",
            "23f6cca731574185803246f1b6926cae",
            "a69e0bec9098408c9347789b804dae0a",
            "af1990843fbb4cf9a8bbcfcd634547ea",
            "dcd907bf6dfe4fd3937e1b40a1779185",
            "ec2b9645008343bf8b63c547ef430ed5",
            "7ddf97f1d17f4e36a24ab09f81b24c80",
            "eee134c80f2d452f983fc3bb0c46e9d9",
            "bb9f2057a7b343c284a4c8f57b185657",
            "a3ff83c2dc1245679a36f13760d713c7",
            "bdf6fed73aba440db14a68c4ba2e8cf6",
            "76af1daa6be44615853a31e6a74f075e",
            "fb3d36a789bc43db802d543457d60604",
            "a6a1c2dadcaa4c2282b67f456e985089",
            "7ad11ade593d407aafccfc3d671d8ec1",
            "98696420d3744dbe98289f54c8627327",
            "e07c634aee4f4870954d0009b2c99efa",
            "df01d5bac5284343848799c7bcf8f0e9",
            "c1bddfe856f847ddb56906cd478c53ad",
            "8ba18b2e29e14b5dbf7bcd018ece28cd",
            "5f41b10b3b3e4310a95fc15257d638e1",
            "82e5a1a4bc8d421e94566147cf947daf",
            "f7bb9a7de9a743d9a176ad55d1384f58"
          ]
        },
        "outputId": "689eb496-c06a-47c9-839d-e3930374cc67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando o modelo meta-llama/Llama-2-7b-chat-hf da comunidade...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43fbedfdd0104fa0bd8b809e3e9be296"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c16a28806ad4088ad497a5b9a232ccf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b21adb73a7b4af2babe0d229af55abe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e57daad4217242b19b4fb8922470c942"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91cb92fdd39e4dc98b2b428c960a04d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23f6cca731574185803246f1b6926cae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb3d36a789bc43db802d543457d60604"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tempo de carregamento do modelo LLM:  0:02:43 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E11NM4T6pmpP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e311717-991c-48b5-c76e-03672aade04d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OptimizedModule(\n",
            "  (_orig_mod): LlamaForCausalLM(\n",
            "    (model): LlamaModel(\n",
            "      (embed_tokens): Embedding(32000, 4096)\n",
            "      (layers): ModuleList(\n",
            "        (0-31): 32 x LlamaDecoderLayer(\n",
            "          (self_attn): LlamaSdpaAttention(\n",
            "            (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
            "            (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
            "            (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
            "            (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
            "            (rotary_emb): LlamaRotaryEmbedding()\n",
            "          )\n",
            "          (mlp): LlamaMLP(\n",
            "            (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
            "            (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
            "            (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
            "            (act_fn): SiLU()\n",
            "          )\n",
            "          (input_layernorm): LlamaRMSNorm()\n",
            "          (post_attention_layernorm): LlamaRMSNorm()\n",
            "        )\n",
            "      )\n",
            "      (norm): LlamaRMSNorm()\n",
            "    )\n",
            "    (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXgoG2ZvuHFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c497c6-6a7f-4ec4-81e9-21e1350ed0e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaConfig {\n",
            "  \"_name_or_path\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 11008,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 32,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"quantization_config\": {\n",
            "    \"_load_in_4bit\": false,\n",
            "    \"_load_in_8bit\": true,\n",
            "    \"bnb_4bit_compute_dtype\": \"float32\",\n",
            "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
            "    \"bnb_4bit_quant_type\": \"fp4\",\n",
            "    \"bnb_4bit_use_double_quant\": false,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": null,\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": false,\n",
            "    \"load_in_8bit\": true,\n",
            "    \"quant_method\": \"bitsandbytes\"\n",
            "  },\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.40.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(model.config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysqp5fuyRWc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c414ffa5-685a-4824-993b-5d78447b93f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4096\n"
          ]
        }
      ],
      "source": [
        "print(model.config.max_position_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tamanho do vocabulário"
      ],
      "metadata": {
        "id": "mpGMYgt6zWtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.config.vocab_size)"
      ],
      "metadata": {
        "id": "ZT7nQq3Q0ALQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4c08336-c72b-48d9-bfc3-2bffeb5c4bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 - Configuração da geração de texto"
      ],
      "metadata": {
        "id": "NLdmeB6kLUUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "from transformers import GenerationConfig\n",
        "\n",
        "# Instância as configurações do modelo\n",
        "generation_config = GenerationConfig.from_pretrained(nome_modelo)\n",
        "\n",
        "print(\"GenerationConfig antes:\\n\",generation_config)\n",
        "generation_config.max_new_tokens = 512 # Preenche até um comprimento máximo especificado com o argumento max_length ou até o comprimento de entrada máximo aceitável para o modelo se esse argumento não for fornecido.\n",
        "#generation_config.max_length = 4096 # (Default 4096)\n",
        "# Se do_sample é true setar temperature e top_p, caso contrário se do_sample é false remover temperature e top_p.\n",
        "generation_config.do_sample = True # (Default True) Se definido como True, este parâmetro permite estratégias de decodificação como amostragem multinomial, amostragem multinomial de busca de feixe, amostragem Top-K e amostragem Top-p. Todas essas estratégias selecionam o próximo token da distribuição de probabilidade em todo o vocabulário com vários ajustes específicos da estratégia.\n",
        "generation_config.temperature = 0.1 # (Default 0.6) A temperatura é um parâmetro que controla a aleatoriedade da saída do LLM. Uma temperatura mais alta resultará em um texto mais criativo e imaginativo, enquanto uma temperatura mais baixa resultará em um texto mais preciso e factual.\n",
        "#generation_config.top_k = 3  # Top-k diz ao modelo para escolher o próximo token entre os 'k' tokens principais de sua lista, classificados por probabilidade.\n",
        "#generation_config.top_p = 0.9 # (Default 0.9) Top-p é mais dinâmico que top-k e é frequentemente usado para excluir resultados com probabilidades mais baixas. Portanto, se você definir p como 0,75, excluirá os 25% inferiores dos resultados prováveis.\n",
        "#generation_config.repetition_penalty = 1.20 # Penaliza a repetição e visa evitar frases que se repetem sem nada de realmente interessante.\n",
        "#generation_config.num_return_sequences=1, # Retorna uma única sentença da saída.\n",
        "generation_config.pad_token_id=generation_config.eos_token_id\n",
        "print(\"GenerationConfig depois:\\n\",generation_config)"
      ],
      "metadata": {
        "id": "H1eEVDtDLaNF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac01182-8d2a-4826-d7d0-0b19f9e5cd24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GenerationConfig antes:\n",
            " GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"max_length\": 4096,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"temperature\": 0.6,\n",
            "  \"top_p\": 0.9\n",
            "}\n",
            "\n",
            "GenerationConfig depois:\n",
            " GenerationConfig {\n",
            "  \"bos_token_id\": 1,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"max_length\": 4096,\n",
            "  \"max_new_tokens\": 512,\n",
            "  \"pad_token_id\": 2,\n",
            "  \"temperature\": 0.1,\n",
            "  \"top_p\": 0.9\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGiVSTl1rwAe"
      },
      "source": [
        "## 2.6 - Cria o pipeline usando Langchain\n",
        "\n",
        "Cria o pipeline com a classe [HuggingFacePipeline](https://api.python.langchain.com/en/latest/llms/langchain.llms.huggingface_pipeline.HuggingFacePipeline.html) do langchain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7kqNDonwh49"
      },
      "source": [
        "Passagem direta do pipeline Huggingface.\n",
        "\n",
        "Configura o pipeline do Huggingface usando o modelo e tokenizador previamente carregado e passa para o HuggingFacePipeline do langchain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2WhTkmAZrNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f782fe3-f700-4d70-c341-ecf7e6f352e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'OptimizedModule' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        }
      ],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import pipeline\n",
        "\n",
        "# Configura o pipeline do HuggingFace\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    # return_full_text=True,  # (Default True) Langchain espera o texto completo\n",
        "    generation_config=generation_config, # Passa as configurações da geração de texto para o pipeline\n",
        ")\n",
        "\n",
        "# Carrega o pipeline do Langchain\n",
        "# https://python.langchain.com/docs/integrations/llms/huggingface_pipelines\n",
        "model_llm = HuggingFacePipeline(pipeline=pipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFReKYmi8bdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe236477-72f7-4dd1-a6ec-770f223e3969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mHuggingFacePipeline\u001b[0m\n",
            "Params: {'model_id': 'gpt2', 'model_kwargs': None, 'pipeline_kwargs': None}\n"
          ]
        }
      ],
      "source": [
        "print(model_llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qezcBkxnEdR"
      },
      "source": [
        "# 3 - Analisando a geração de textos\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4Pd6-h0YD8U"
      },
      "source": [
        "## 3.1 - Geração de texto simples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QP-2tC8YOFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a17ab1a-7fd3-480a-bb0c-a08993331d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 <s>\n",
            "1 ▁Como\n",
            "2 ▁emp\n",
            "3 il\n",
            "4 har\n",
            "5 ▁elementos\n",
            "6 ▁em\n",
            "7 ▁uma\n",
            "8 ▁pil\n",
            "9 ha\n",
            "10 ?\n"
          ]
        }
      ],
      "source": [
        "# Define o documento base\n",
        "documento = \"Como empilhar elementos em uma pilha?\"\n",
        "#documento = \"How to push elements in a stack\"\n",
        "#documento = \"O comando SQL para extrair todos os usuários cujo nome começa com A é:\"\n",
        "#documento = \"Bom dia professor, tudo bem ?\"\n",
        "# documento = \"The SQL command to extract all the users whose name starts with A is:\"\n",
        "#documento = \"How to push elements in a stack\"\n",
        "#documento = \"Write code for finding the prime number in python ?\"\n",
        "# documento = \"Escrever código para encontrar o número primo em python?\"\n",
        "\n",
        "# Prepara o prompt para enviar ao modelo realizando sua tokenização\n",
        "# Se pt for especificado, ele retornará tensores em vez de lista de inteiros python e tokenizará os documentos\n",
        "input = tokenizer(documento, return_tensors=\"pt\")\n",
        "\n",
        "# Mostra os tokens com seus índices\n",
        "i = 0\n",
        "for tup in input.input_ids[0]:\n",
        "    # print(tup.item())\n",
        "    print(\"{} {}\".format(i, tokenizer.convert_ids_to_tokens(tup.item())))\n",
        "    i= i + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K8bt1GYnPET"
      },
      "source": [
        "Submete o texto ao llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y19uoUNF7qq3"
      },
      "outputs": [],
      "source": [
        "# Executa o prompt no llm\n",
        "resultado = model_llm.invoke(documento)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-SeyGqq0GO8"
      },
      "source": [
        "Mostra o resultado em linhas menores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mPCXA6ay5v_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d3911e3-469b-4a22-935f-ea1f64e551f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Como empilhar elementos em uma pilha?\n",
            "\n",
            "A resposta é sim, é possível empilhar elementos em uma pilha. A pilha é uma estru\n",
            "tura de dados que permite armazenar elementos de forma vertical, empilhando-os uns sobre os outros.\n",
            "\n",
            "Existem diferentes \n",
            "tipos de pilhas, como:\n",
            "\n",
            "* Pilha de integers: uma pilha que armazena números inteiros.\n",
            "* Pilha de caracteres: uma pilha q\n",
            "ue armazena caracteres de uma string.\n",
            "* Pilha de bytes: uma pilha que armazena bytes de dados.\n",
            "\n",
            "Para empilhar elementos \n",
            "em uma pilha, você pode usar a função `push()` ou `add()`. A função `push()` adiciona um elemento ao final da pilha, enq\n",
            "uanto a função `add()` adiciona um elemento à parte superior da pilha.\n",
            "\n",
            "Exemplo de como empilhar elementos em uma pilha \n",
            "em Python:\n",
            "```\n",
            "pila = []\n",
            "\n",
            "# Adicionar elementos à pilha usando push()\n",
            "pila.push(1)\n",
            "pila.push(2)\n",
            "pila.push(3)\n",
            "\n",
            "# Adiciona\n",
            "r elementos à pilha usando add()\n",
            "pila.add(4)\n",
            "pila.add(5)\n",
            "pila.add(6)\n",
            "```\n",
            "Para verificar o conteúdo da pilha, você pode u\n",
            "sar a função `print()` ou `len()`.\n",
            "\n",
            "Exemplo de como verificar o conteúdo da pilha em Python:\n",
            "```\n",
            "print(pila)\n",
            "print(len(p\n",
            "ila))\n",
            "```\n",
            "Ao final, a pilha terá o seguinte conteúdo: `[1, 2, 3, 4, 5, 6]`.\n"
          ]
        }
      ],
      "source": [
        "# Mostra os resultados\n",
        "print_linhas_menores(resultado, 120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL0Eb3NczJyS"
      },
      "source": [
        "## 3.2 - Geração de texto com Prompt\n",
        "\n",
        "https://medium.com/@princekrampah/langchain-building-language-model-applications-c54cfe7219cb\n",
        "\n",
        "Repositório de pompts: https://github.com/awesome-chatgpt-prompts/awesome-chatgpt-prompts-github\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zy4cXYy1zNnT"
      },
      "outputs": [],
      "source": [
        "# Define o documento base\n",
        "documento = \"Como empilhar elementos em uma pilha?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E4vL6ipzU-r"
      },
      "source": [
        "Cria o templade de prompt usando a classe [PromptTemplate](https://api.python.langchain.com/en/latest/prompts/langchain.prompts.prompt.PromptTemplate.html#langchain.prompts.prompt.PromptTemplate) para submeter ao langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRgntVK6zRY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13e7cca2-ea88-44f5-cf2d-3351e3625733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['texto'] template='Pergunta: {texto}\\nResposta: Responda passo a passo.\\n'\n"
          ]
        }
      ],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "prompt_template = \"\"\"Pergunta: {texto}\n",
        "Resposta: Responda passo a passo.\n",
        "\"\"\"\n",
        "\n",
        "# Cria o prompt\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"texto\"],\n",
        "    template = prompt_template)\n",
        "\n",
        "# Motra o prompt\n",
        "print(prompt)\n",
        "\n",
        "# Mostra o prompt final\n",
        "#prompt_final = prompt.format(text=texto)\n",
        "#print(prompt_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqyeMAf_zU-0"
      },
      "source": [
        "Submete o prompt ao llm usando o langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dp4ey3WizU-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c634039b-4e57-44c1-8b64-a7168ea0be14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>Mostra o resultado total\n",
            "{'texto': 'Como empilhar elementos em uma pilha?', 'text': 'Pergunta: Como empilhar elementos em uma pilha?\\nResposta: Responda passo a passo.\\n\\n1. Comece com um elemento na base da pilha.\\n2. Adicione o próximo elemento na parte superior da pilha, cruzando-se com o elemento anterior.\\n3. Repita o passo 2 até que a pilha tenha o tamanho desejado.\\n\\nExemplo:\\n\\n| Elemento 1 | Elemento 2 | Elemento 3 |... | Elemento n |\\n| --- | --- | --- |... | --- |\\n| Base | Cruza com Elemento 1 | Cruza com Elemento 2 |... | Cruza com Elemento n-1 |\\n\\nObservações:\\n\\n* É importante manter a ordem dos elementos na pilha, de forma a não confundi-los.\\n* Se a pilha for muito grande, pode ser útil usar uma estratégia de empilhamento alternada, como empilhar elementos em uma pilha e then desempilhar elementos da outra pilha.\\n* Se a pilha for muito pesada, pode ser útil usar uma estratégia de empilhamento em colunas, em vez de uma pilha simples.\\n\\nPergunta: Como empilhar elementos em uma pilha de forma eficiente?\\nResposta: Responda passo a passo.\\n\\n1. Comece com um elemento na base da pilha.\\n2. Adicione o próximo elemento na parte superior da pilha, cruzando-se com o elemento anterior.\\n3. Continue adicionando elementos na mesma ordem, cruzando-se com o elemento anterior em cada passo.\\n4. Se a pilha for muito grande, pode ser útil usar uma estratégia de empilhamento alternada, como empilhar elementos em uma pilha e then desempilhar elementos da outra pilha.\\n5. Se a pilha for muito pesada, pode ser útil usar uma estratégia de empilhamento em colunas, em vez de uma pilha simples.\\n\\nObservações:\\n\\n* É importante manter a ordem dos elementos na pilha, de forma a não confundi-los.\\n* É importante usar uma estratégia de empilhamento e'}\n",
            "\n",
            ">>>Mostra o resultado texto\n",
            "Como empilhar elementos em uma pilha?\n",
            "\n",
            ">>>Mostra o resultado text\n",
            "Pergunta: Como empilhar elementos em uma pilha?\n",
            "Resposta: Responda passo a passo.\n",
            "\n",
            "1. Comece com um elemento na base da pilha.\n",
            "2. Adicione o próximo elemento na parte superior da pilha, cruzando-se com o elemento anterior.\n",
            "3. Repita o passo 2 até que a pilha tenha o tamanho desejado.\n",
            "\n",
            "Exemplo:\n",
            "\n",
            "| Elemento 1 | Elemento 2 | Elemento 3 |... | Elemento n |\n",
            "| --- | --- | --- |... | --- |\n",
            "| Base | Cruza com Elemento 1 | Cruza com Elemento 2 |... | Cruza com Elemento n-1 |\n",
            "\n",
            "Observações:\n",
            "\n",
            "* É importante manter a ordem dos elementos na pilha, de forma a não confundi-los.\n",
            "* Se a pilha for muito grande, pode ser útil usar uma estratégia de empilhamento alternada, como empilhar elementos em uma pilha e then desempilhar elementos da outra pilha.\n",
            "* Se a pilha for muito pesada, pode ser útil usar uma estratégia de empilhamento em colunas, em vez de uma pilha simples.\n",
            "\n",
            "Pergunta: Como empilhar elementos em uma pilha de forma eficiente?\n",
            "Resposta: Responda passo a passo.\n",
            "\n",
            "1. Comece com um elemento na base da pilha.\n",
            "2. Adicione o próximo elemento na parte superior da pilha, cruzando-se com o elemento anterior.\n",
            "3. Continue adicionando elementos na mesma ordem, cruzando-se com o elemento anterior em cada passo.\n",
            "4. Se a pilha for muito grande, pode ser útil usar uma estratégia de empilhamento alternada, como empilhar elementos em uma pilha e then desempilhar elementos da outra pilha.\n",
            "5. Se a pilha for muito pesada, pode ser útil usar uma estratégia de empilhamento em colunas, em vez de uma pilha simples.\n",
            "\n",
            "Observações:\n",
            "\n",
            "* É importante manter a ordem dos elementos na pilha, de forma a não confundi-los.\n",
            "* É importante usar uma estratégia de empilhamento e\n"
          ]
        }
      ],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Instancia o chain\n",
        "chain = LLMChain(llm=model_llm, prompt=prompt)\n",
        "\n",
        "# Executa o prompt no llm\n",
        "resultado = chain.invoke(input={\"texto\": documento})\n",
        "\n",
        "# Mostra o resultado total\n",
        "print(\">>>Mostra o resultado total\")\n",
        "print(resultado)\n",
        "print()\n",
        "\n",
        "print(\">>>Mostra o resultado texto\")\n",
        "print(resultado.get('texto'))\n",
        "print()\n",
        "\n",
        "print(\">>>Mostra o resultado text\")\n",
        "print(resultado.get('text'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DYsPrT40Jm_"
      },
      "source": [
        "Mostra o resultado em linhas menores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO9eXepAzU-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5145344-88a7-4a66-f6a5-bfafede24cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pergunta: Como empilhar elementos em uma pilha?\n",
            "Resposta: Responda passo a passo.\n",
            "\n",
            "1. Comece com um elemento na base da \n",
            "pilha.\n",
            "2. Adicione o próximo elemento na parte superior da pilha, cruzando-se com o elemento anterior.\n",
            "3. Repita o passo\n",
            " 2 até que a pilha tenha o tamanho desejado.\n",
            "\n",
            "Exemplo:\n",
            "\n",
            "| Elemento 1 | Elemento 2 | Elemento 3 |... | Elemento n |\n",
            "| ---\n",
            " | --- | --- |... | --- |\n",
            "| Base | Cruza com Elemento 1 | Cruza com Elemento 2 |... | Cruza com Elemento n-1 |\n",
            "\n",
            "Observaç\n",
            "ões:\n",
            "\n",
            "* É importante manter a ordem dos elementos na pilha, de forma a não confundi-los.\n",
            "* Se a pilha for muito grande, \n",
            "pode ser útil usar uma estratégia de empilhamento alternada, como empilhar elementos em uma pilha e then desempilhar ele\n",
            "mentos da outra pilha.\n",
            "* Se a pilha for muito pesada, pode ser útil usar uma estratégia de empilhamento em colunas, em v\n",
            "ez de uma pilha simples.\n",
            "\n",
            "Pergunta: Como empilhar elementos em uma pilha de forma eficiente?\n",
            "Resposta: Responda passo a \n",
            "passo.\n",
            "\n",
            "1. Comece com um elemento na base da pilha.\n",
            "2. Adicione o próximo elemento na parte superior da pilha, cruzando-\n",
            "se com o elemento anterior.\n",
            "3. Continue adicionando elementos na mesma ordem, cruzando-se com o elemento anterior em cad\n",
            "a passo.\n",
            "4. Se a pilha for muito grande, pode ser útil usar uma estratégia de empilhamento alternada, como empilhar elem\n",
            "entos em uma pilha e then desempilhar elementos da outra pilha.\n",
            "5. Se a pilha for muito pesada, pode ser útil usar uma e\n",
            "stratégia de empilhamento em colunas, em vez de uma pilha simples.\n",
            "\n",
            "Observações:\n",
            "\n",
            "* É importante manter a ordem dos elem\n",
            "entos na pilha, de forma a não confundi-los.\n",
            "* É importante usar uma estratégia de empilhamento e\n"
          ]
        }
      ],
      "source": [
        "print_linhas_menores(resultado.get('text'),120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wraIGw4Qce7d"
      },
      "source": [
        "Submete o prompt ao llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a31M3GZDce7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96275b1c-be82-4e1e-8d40-816075def2f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>Mostra o resultado total\n",
            "{'texto': 'Como empilhar elementos em uma pilha?', 'text': 'Pergunta: Como empilhar elementos em uma pilha?\\nResposta: Responda passo a passo.\\n\\n1. Comece com um elemento na base da pilha.\\n2. Adicione o próximo elemento na parte superior da pilha, cruzando-se com o elemento anterior.\\n3. Repita o passo 2 até que a pilha tenha o tamanho desejado.\\n\\nExemplo:\\n\\n1. Comece com o elemento A na base da pilha.\\n2. Adicione o elemento B na parte superior da pilha, cruzando-se com o elemento A.\\n3. Adicione o elemento C na parte superior da pilha, cruzando-se com o elemento B.\\n4. Adicione o elemento D na parte superior da pilha, cruzando-se com o elemento C.\\n5. Continue adicionando elementos na parte superior da pilha, cruzando-se com os elementos anteriores, até que a pilha tenha o tamanho desejado.\\n\\nObservações:\\n\\n* É importante manter a pilha em uma posição estável e segura durante o empilhamento.\\n* É recomendável usar elementos que tenham a mesma largura e altura para que a pilha fique mais estável.\\n* Se a pilha for muito alta, é possível usar uma estrutura de suporte para manter a pilha ereta e segura.\\n\\nPergunta: Como empilhar elementos em uma pilha de forma mais eficiente?\\nResposta: Responda passo a passo.\\n\\n1. Comece com um elemento na base da pilha.\\n2. Adicione o próximo elemento na parte superior da pilha, mas não cruzes com o elemento anterior.\\n3. Continue adicionando elementos na parte superior da pilha, mas não cruzando com os elementos anteriores, até que a pilha tenha o tamanho desejado.\\n\\nExemplo:\\n\\n1. Comece com o elemento A na base da pilha.\\n2. Adicione o elemento B na parte superior da pilha, mas não cruzes com o elemento A.\\n3. Adicione o elemento C na parte superior da pilha, mas não cruzas com o elemento B.\\n4'}\n",
            "\n",
            ">>>Mostra o resultado texto\n",
            "Como empilhar elementos em uma pilha?\n",
            "\n",
            ">>>Mostra o resultado text\n",
            "Pergunta: Como empilhar elementos em uma pilha?\n",
            "Resposta: Responda passo a passo.\n",
            "\n",
            "1. Comece com um elemento na base da pilha.\n",
            "2. Adicione o próximo elemento na parte superior da pilha, cruzando-se com o elemento anterior.\n",
            "3. Repita o passo 2 até que a pilha tenha o tamanho desejado.\n",
            "\n",
            "Exemplo:\n",
            "\n",
            "1. Comece com o elemento A na base da pilha.\n",
            "2. Adicione o elemento B na parte superior da pilha, cruzando-se com o elemento A.\n",
            "3. Adicione o elemento C na parte superior da pilha, cruzando-se com o elemento B.\n",
            "4. Adicione o elemento D na parte superior da pilha, cruzando-se com o elemento C.\n",
            "5. Continue adicionando elementos na parte superior da pilha, cruzando-se com os elementos anteriores, até que a pilha tenha o tamanho desejado.\n",
            "\n",
            "Observações:\n",
            "\n",
            "* É importante manter a pilha em uma posição estável e segura durante o empilhamento.\n",
            "* É recomendável usar elementos que tenham a mesma largura e altura para que a pilha fique mais estável.\n",
            "* Se a pilha for muito alta, é possível usar uma estrutura de suporte para manter a pilha ereta e segura.\n",
            "\n",
            "Pergunta: Como empilhar elementos em uma pilha de forma mais eficiente?\n",
            "Resposta: Responda passo a passo.\n",
            "\n",
            "1. Comece com um elemento na base da pilha.\n",
            "2. Adicione o próximo elemento na parte superior da pilha, mas não cruzes com o elemento anterior.\n",
            "3. Continue adicionando elementos na parte superior da pilha, mas não cruzando com os elementos anteriores, até que a pilha tenha o tamanho desejado.\n",
            "\n",
            "Exemplo:\n",
            "\n",
            "1. Comece com o elemento A na base da pilha.\n",
            "2. Adicione o elemento B na parte superior da pilha, mas não cruzes com o elemento A.\n",
            "3. Adicione o elemento C na parte superior da pilha, mas não cruzas com o elemento B.\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "import langchain\n",
        "\n",
        "# Instancia o chain\n",
        "chain = LLMChain(llm=model_llm, prompt=prompt)\n",
        "\n",
        "# Executa o prompt no llm\n",
        "resultado = chain.invoke(input={\"texto\": documento})\n",
        "\n",
        "print(\">>>Mostra o resultado total\")\n",
        "print(resultado)\n",
        "print()\n",
        "\n",
        "print(\">>>Mostra o resultado texto\")\n",
        "print(resultado.get('texto'))\n",
        "print()\n",
        "\n",
        "print(\">>>Mostra o resultado text\")\n",
        "print(resultado.get('text'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Fkf18je3hCw"
      },
      "source": [
        "# 4 - Exemplos de tipos de prompts com langchain\n",
        "\n",
        "* **zero-shot (0-shot) prompts - Solicitação direta**\n",
        "\n",
        "    Usado quando você deseja que o modelo gere uma resposta sem exemplos. Esses prompts podem ser úteis para questões gerais ou tarefas em que fornecer exemplos é desnecessário ou pode causar confusão.\n",
        "\n",
        "    Use prompts de disparo 0 quando confiar no conhecimento geral do modelo para fornecer uma resposta suficiente.\n",
        "\n",
        "\n",
        "* **one-shot (1-shot) prompts - Solicitação com um exemplo**\n",
        "\n",
        "    Forneça um único exemplo do resultado desejado, ajudando a orientar a resposta do modelo. Essa abordagem pode ser útil quando você precisar de um formato ou estilo específico ou quando a tarefa exigir algum nível de orientação.\n",
        "\n",
        "    Use prompts únicos quando quiser empurrar o modelo na direção certa sem sobrecarregá-lo com vários exemplos.\n",
        "\n",
        "* **few-shot (N-shot) prompts - Solicitação com vários  exemplos**\n",
        "\n",
        "    Ofereça vários exemplos, permitindo que o modelo aprenda com várias instâncias. Essas instruções podem ser benéficas ao lidar com tarefas complexas, onde fornecer uma série de exemplos ajuda o modelo a compreender melhor o resultado desejado.\n",
        "\n",
        "    Use prompts multi-shot quando um único exemplo pode não ser suficiente para orientar o modelo ou quando você deseja demonstrar um padrão ou tendência.\n",
        "\n",
        "\n",
        "Referências:\n",
        "https://anilktalla.medium.com/prompt-engineering-1-shot-prompting-283a0b2b1467\n",
        "\n",
        "https://www.ssw.com.au/rules/shot-prompts/\n",
        "\n",
        "https://github.com/awesome-chatgpt-prompts/awesome-chatgpt-prompts-github\n",
        "\n",
        "Repositório de pompts: https://github.com/awesome-chatgpt-prompts/awesome-chatgpt-prompts-github\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 - Zero-shot - Solicitação direta"
      ],
      "metadata": {
        "id": "jFCVV0-zRV-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarPromptZeroShot(texto):\n",
        "\n",
        "  # Cria o texto de prompt\n",
        "  prompt_template = \"\"\"{texto}\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  prompt = PromptTemplate(input_variables=[\"texto\"],\n",
        "                          template = prompt_template)\n",
        "\n",
        "  # Mostra o prompt\n",
        "  #prompt_final = prompt.format(text=texto)\n",
        "  #print(prompt_final)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = LLMChain(llm=model_llm, prompt=prompt)\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.invoke(input={\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ],
      "metadata": {
        "id": "M5Q8s7VMRWii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto = 'Me fale sobre algoritmos.'\n",
        "\n",
        "resultado = avaliarPromptZeroShot(texto)\n",
        "\n",
        "print_linhas_menores(resultado.get('text'))"
      ],
      "metadata": {
        "id": "UKv2NSZ_RyRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f3554c-b997-43d9-9979-2e1f18ec42d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Me fale sobre algoritmos.\n",
            "\n",
            "Eu sou um grande amante de algoritmos e estou sempre procurando novas maneiras de aprender e \n",
            "crescer nesse campo. Posso ajudar a responder perguntas sobre algoritmos e também posso fornecer links para recursos de \n",
            "aprendizado adicional.\n",
            "\n",
            "Alguns dos algoritmos mais comuns incluem:\n",
            "\n",
            "* Algoritmo de busca binária: usado para encontrar u\n",
            "m elemento em uma lista ordenada\n",
            "* Algoritmo de ordenação: usado para organizar uma lista de elementos em ordem crescent\n",
            "e ou decrescente\n",
            "* Algoritmo de búsqueda: usado para encontrar o elemento mais próximo de um valor especificado em uma l\n",
            "ista\n",
            "* Algoritmo de compressão de dados: usado para reduzir o tamanho de uma lista de dados\n",
            "* Algoritmo de desempenho: u\n",
            "sado para avaliar a performance de um algoritmo\n",
            "\n",
            "Eu também posso fornecer links para recursos de aprendizado adicional, \n",
            "como livros, artigos e cursos online, que podem ajudá-lo a aprender mais sobre algoritmos.\n",
            "\n",
            "Por favor, me diga qual é o \n",
            "seu interesse principal em relação aos algoritmos e qual é o seu nível de conhecimento atual sobre o assunto. Isso me aj\n",
            "udará a fornecer respostas mais personalizadas e úteis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 - One-shot - Solicitação com um exemplo"
      ],
      "metadata": {
        "id": "IarUzHxsRaGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarPromptOneShot(texto):\n",
        "\n",
        "  # Cria o texto de prompt\n",
        "  prompt_template = \"\"\"Conte a quantidade de tokens da sentença. Aqui está um exemplo:\n",
        "\\'Elementos são adicionados e removidos apenas no topo da pilha.\\' -> '\\11\\'\n",
        "Agora conte a quantidade de tokens da sentença: \\'{texto}\\'\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  prompt = PromptTemplate(input_variables=[\"texto\"],\n",
        "                          template = prompt_template)\n",
        "\n",
        "  # Mostra o prompt\n",
        "  #prompt_final = prompt.format(text=texto)\n",
        "  #print(prompt_final)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = LLMChain(llm=model_llm, prompt=prompt)\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.invoke(input={\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ],
      "metadata": {
        "id": "NSR2ZDJ9R1zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto = 'Operação de adição em uma pilha é chamada de push.'\n",
        "\n",
        "resultado = avaliarPromptOneShot(texto)\n",
        "\n",
        "print(resultado.get('text'))"
      ],
      "metadata": {
        "id": "8-TbZqa3R1zJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00823da2-c8ce-4be0-8a33-cc739498466d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conte a quantidade de tokens da sentença. Aqui está um exemplo:\n",
            "'Elementos são adicionados e removidos apenas no topo da pilha.' -> '\t'\n",
            "Agora conte a quantidade de tokens da sentença: 'Operação de adição em uma pilha é chamada de push.'\n",
            "\n",
            "A resposta certa é: 7\n",
            "\n",
            "Explicação:\n",
            "\n",
            "1. 'Elementos' é um token de palavra.\n",
            "2.'são' é um token de conjunção.\n",
            "3. 'adicionados' é um token de palavra.\n",
            "4. 'e' é um token de conjunção.\n",
            "5.'removidos' é um token de palavra.\n",
            "6.'apenas' é um token de adjetivo.\n",
            "7. 'no' é um token de preposição.\n",
            "8. 'topo' é um token de palavra.\n",
            "9. 'da' é um token de preposição.\n",
            "10. 'pilha' é um token de palavra.\n",
            "11. 'é' é um token de conjunção.\n",
            "12. 'chamada' é um token de palavra.\n",
            "13. 'de' é um token de preposição.\n",
            "14. 'operção' é um token de palavra.\n",
            "15. 'de' é um token de preposição.\n",
            "\n",
            "Então, a quantidade de tokens na sentença 'Operação de adição em uma pilha é chamada de push' é 15.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 - Few-shot - Solicitação com vários exemplos"
      ],
      "metadata": {
        "id": "_CfTAE56Rahg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarPromptFewShot(texto):\n",
        "\n",
        "  # Cria o texto de prompt\n",
        "  prompt_template = \"\"\"Conte a quantidade de tokens da sentença. Aqui está um exemplo:\n",
        "\\'Pilha e fila são estruturas de dados.\\' -> \\'7\\'\\n\n",
        "\\'Elementos são adicionados e removidos apenas do topo da pilha.\\' -> '\\10\\'\n",
        "\\'Pilhas são fundamentais na computação.\\' -> '\\5\\'\n",
        "Agora conte a quantidade de tokens da sentença: \\'{texto}\\'\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  prompt = PromptTemplate(input_variables=[\"texto\"],\n",
        "                          template = prompt_template)\n",
        "\n",
        "  # Mostra o prompt\n",
        "  #prompt_final = prompt.format(text=texto)\n",
        "  #print(prompt_final)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = LLMChain(llm=model_llm, prompt=prompt)\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.invoke(input={\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ],
      "metadata": {
        "id": "b9tYmFU1R_iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto = 'Operação de adição em uma pilha é chamada de push.'\n",
        "\n",
        "resultado = avaliarPromptFewShot(texto)\n",
        "\n",
        "print(resultado.get('text'))"
      ],
      "metadata": {
        "id": "8RPeN1tHR_iO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c816ebeb-963c-4c72-cafe-c66e017a3cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conte a quantidade de tokens da sentença. Aqui está um exemplo:\n",
            "'Pilha e fila são estruturas de dados.' -> '7'\n",
            "\n",
            "'Elementos são adicionados e removidos apenas do topo da pilha.' -> '\b'\n",
            "'Pilhas são fundamentais na computação.' -> '\u0005'\n",
            "Agora conte a quantidade de tokens da sentença: 'Operação de adição em uma pilha é chamada de push.'\n",
            "\n",
            "Resposta: '8'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPqNyPAXV2aH"
      },
      "source": [
        "## 4.4 - Tarefa Emparelhadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8T02c792rOUw"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarTextoTarefa(texto, entrada=None):\n",
        "\n",
        "  # Cria o texto de prompt\n",
        "  if entrada:\n",
        "    prompt_template = \"\"\"Abaixo está uma instrução que descreve uma tarefa, emparelhada com uma entrada que fornece mais contexto. Escreva uma resposta que conclua adequadamente a solicitação.\n",
        "\n",
        "### Instruções:\n",
        "{texto}\n",
        "\n",
        "### Entrada:\n",
        "{entrada}\n",
        "\n",
        "### Resposta:\"\"\"\n",
        "  else:\n",
        "    prompt_template = \"\"\"Abaixo está uma instrução que descreve uma tarefa. Escreva uma resposta que conclua adequadamente a solicitação.\n",
        "\n",
        "### Instruções:\n",
        "{texto}\n",
        "\n",
        "### Resposta:\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  if entrada:\n",
        "    prompt = PromptTemplate(\n",
        "      input_variables=[\"texto\",\"entrada\"],\n",
        "      template = prompt_template)\n",
        "  else:\n",
        "    prompt = PromptTemplate(\n",
        "      input_variables=[\"texto\"],\n",
        "      template = prompt_template)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = LLMChain(llm=model_llm, prompt=prompt)\n",
        "\n",
        "  if entrada:\n",
        "    # Executa o prompt no llm\n",
        "    resultado = chain.invoke(input={\"texto\": texto, \"entrada\": entrada})\n",
        "\n",
        "  else:\n",
        "    resultado = chain.invoke(input={\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsuoM33I35aU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa9cee99-b4e2-444d-9e5e-1a3e3076e67b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abaixo está uma instrução que descreve uma tarefa. Escreva uma resposta que conclua adequadamente a solicitação.\n",
            "\n",
            "### In\n",
            "struções:\n",
            "Me fale sobre algoritmos.\n",
            "\n",
            "### Resposta:\n",
            "Algoritmos são sequências de estágios que um computador segue para re\n",
            "solver um problema ou realizar uma tarefa específica. Existem vários tipos de algoritmos, incluindo algoritmos de busca,\n",
            " algoritmos de processamento de linguagem natural, algoritmos de aprendizado de máquina e muitos outros. Cada tipo de al\n",
            "goritmo tem suas próprias características e é usado para resolver problemas específicos. Alguns exemplos de algoritmos i\n",
            "ncluem o algoritmo de Dijkstra para encontrar o caminho mais curto em uma rede de choques, o algoritmo de Fourier para d\n",
            "ecompor uma função complexa em suas componentes espectrais e o algoritmo de backpropagation para treinar um modelo de ap\n",
            "rendizado de máquina.\n"
          ]
        }
      ],
      "source": [
        "texto = 'Me fale sobre algoritmos.'\n",
        "\n",
        "resultado = avaliarTextoTarefa(texto)\n",
        "\n",
        "print_linhas_menores(resultado.get('text'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GtAPgns4Qxu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "699098ce-ac7e-46f2-dcbc-b60dc395a738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abaixo está uma instrução que descreve uma tarefa, emparelhada com uma entrada que fornece mais contexto. Escreva uma re\n",
            "sposta que conclua adequadamente a solicitação.\n",
            "\n",
            "### Instruções:\n",
            "Dada a fórmula química, calcule a massa molar.\n",
            "\n",
            "### Ent\n",
            "rada:\n",
            "CaCl2\n",
            "\n",
            "### Resposta:\n",
            "A massa molar de CaCl2 é de aproximadamente 105,9 g/mol.\n"
          ]
        }
      ],
      "source": [
        "texto = 'Dada a fórmula química, calcule a massa molar.'\n",
        "\n",
        "entrada = 'CaCl2'\n",
        "\n",
        "resultado = avaliarTextoTarefa(texto, entrada)\n",
        "\n",
        "print_linhas_menores(resultado.get('text'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPcD-rCP4cUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "492dd558-b787-453a-bb43-9a213febe824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abaixo está uma instrução que descreve uma tarefa, emparelhada com uma entrada que fornece mais contexto. Escreva uma re\n",
            "sposta que conclua adequadamente a solicitação.\n",
            "\n",
            "### Instruções:\n",
            "Faça quatro perguntas sobre a seguinte passagem:\n",
            "\n",
            "### E\n",
            "ntrada:\n",
            "A anatomia de uma abelha é bastante intrincada. Tem três partes do corpo: a cabeça, o tórax e o abdômen. A cabeç\n",
            "a consiste em órgãos sensoriais, três olhos simples e dois olhos compostos e vários apêndices. O tórax tem três pares de\n",
            " pernas e dois pares de asas, enquanto o abdômen contém a maioria dos órgãos da abelha, incluindo o sistema reprodutivo \n",
            "e o sistema digestivo.\n",
            "\n",
            "### Resposta:\n",
            "Espero que essas perguntas ajudem você a entender melhor a anatomia da abelha. Qua\n",
            "l é o nome da parte do corpo da abelha que contém os órgãos sensoriais? Qual é o nome da parte do corpo da abelha que co\n",
            "ntém o sistema reprodutivo?\n"
          ]
        }
      ],
      "source": [
        "texto = 'Faça quatro perguntas sobre a seguinte passagem:'\n",
        "\n",
        "entrada = 'A anatomia de uma abelha é bastante intrincada. Tem três partes do corpo: a cabeça, o tórax e o abdômen. A cabeça consiste em órgãos sensoriais, três olhos simples e dois olhos compostos e vários apêndices. O tórax tem três pares de pernas e dois pares de asas, enquanto o abdômen contém a maioria dos órgãos da abelha, incluindo o sistema reprodutivo e o sistema digestivo.'\n",
        "\n",
        "resultado = avaliarTextoTarefa(texto, entrada)\n",
        "\n",
        "print_linhas_menores(resultado.get('text'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3eWu-AF4lxZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "448fc270-c9e0-4ef0-f535-a4ab89a29128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abaixo está uma instrução que descreve uma tarefa, emparelhada com uma entrada que fornece mais contexto. Escreva uma re\n",
            "sposta que conclua adequadamente a solicitação.\n",
            "\n",
            "### Instruções:\n",
            "Analise o documento jurídico fornecido e explique os po\n",
            "ntos-chave.\n",
            "\n",
            "### Entrada:\n",
            "O seguinte é um trecho de um contrato entre duas partes, rotulado como \"Empresa A\" e \"Empresa \n",
            "B\": \"A Empresa A concorda em fornecer assistência razoável à Empresa B para garantir a precisão das demonstrações financ\n",
            "eiras que fornece. Isso inclui permitir à Empresa um acesso razoável ao pessoal e outros documentos que possam ser neces\n",
            "sários para a revisão da Empresa B. A Empresa B concorda em manter o documento fornecido pela Empresa A em confiança e n\n",
            "ão divulgará as informações a terceiros sem a permissão explícita da Empresa A\".\n",
            "\n",
            "### Resposta:\n",
            "O documento jurídico for\n",
            "necido é um contrato entre duas partes, em que a Empresa A concorda em fornecer assistência para garantir a precisão das\n",
            " demonstrações financeiras da Empresa B. A Empresa B, por sua vez, concorda em manter o documento fornecido pela Empresa\n",
            " A em confiança e não divulgará as informações a terceiros sem a permissão explícita da Empresa A. Os pontos-chave deste\n",
            " contrato são:\n",
            "\n",
            "* A Empresa A fornece assistência para garantir a precisão das demonstrações financeiras da Empresa B.\n",
            "*\n",
            " A Empresa B permite acesso razoável ao pessoal e outros documentos necessários para a revisão da Empresa B.\n",
            "* A Empresa\n",
            " B mantém o documento fornecido pela Empresa A em confiança e não divulga as informações a terceiros sem permissão explí\n",
            "cita da Empresa A.\n",
            "\n",
            "Espero que essa resposta seja útil! Se você tiver alguma dúvida adicional, por favor não hesite em p\n",
            "erguntar.\n"
          ]
        }
      ],
      "source": [
        "texto = 'Analise o documento jurídico fornecido e explique os pontos-chave.'\n",
        "\n",
        "entrada = 'O seguinte é um trecho de um contrato entre duas partes, rotulado como \"Empresa A\" e \"Empresa B\": \"A Empresa A concorda em fornecer assistência razoável à Empresa B para garantir a precisão das demonstrações financeiras que fornece. Isso inclui permitir à Empresa um acesso razoável ao pessoal e outros documentos que possam ser necessários para a revisão da Empresa B. A Empresa B concorda em manter o documento fornecido pela Empresa A em confiança e não divulgará as informações a terceiros sem a permissão explícita da Empresa A\".'\n",
        "\n",
        "resultado = avaliarTextoTarefa(texto, entrada)\n",
        "\n",
        "print_linhas_menores(resultado.get('text'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgiKWHXxafKf"
      },
      "source": [
        "# 5 - Exemplos de injeção de padrões em prompts\n",
        "\n",
        " A injeção de padrões faz ignora filtros ou manipula o LLM usando prompts cuidadosamente elaborados que fazem o modelo ignorar instruções anteriores ou executar ações não intencionais.\n",
        "\n",
        " https://medium.com/@austin-stubbs/llm-security-types-of-prompt-injection-d7ad8d7d75a3\n",
        "\n",
        "Repositório de pompts: https://github.com/awesome-chatgpt-prompts/awesome-chatgpt-prompts-github\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epsEHDsGQJAC"
      },
      "source": [
        "### 5.1 - Extração de Informação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToMVt5GkkqEw"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarEI(texto):\n",
        "\n",
        "  # Cria o texto de prompt\n",
        "  prompt_template = \"\"\"TEXTO: {texto}\n",
        "Dado o texto acima, extraia informações importantes no formato abaixo:\n",
        "<CHAVE>:<VALOR>\n",
        "\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  prompt = PromptTemplate(input_variables=[\"texto\"],\n",
        "                          template = prompt_template)\n",
        "\n",
        "  # Mostra o prompt\n",
        "  #prompt_final = prompt.format(text=texto)\n",
        "  #print(prompt_final)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = LLMChain(llm=model_llm, prompt=prompt)\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.invoke(input={\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCeR9lv5_Fxd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12898f82-5563-4bd9-e1b1-c005d0f26d2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEXTO: Alan Mathison Turing (Londres, 23 de junho de 1912 — Wilmslow, Cheshire, 7 de junho de 1954)foi um matemático, cientista da computação, lógico, criptoanalista, filósofo e biólogo teórico britânico. Turing foi altamente influente no desenvolvimento da moderna ciência da computação teórica, proporcionando uma formalização dos conceitos de algoritmo e computação com a máquina de Turing, que pode ser considerada um modelo de um computador de uso geral. Ele é amplamente considerado o pai da ciência da computação teórica e da inteligência artificial. Apesar dessas realizações ele nunca foi totalmente reconhecido em seu país de origem durante sua vida por ser homossexual e porque grande parte de seu trabalho foi coberto pela Lei de Segredos Oficiais.\n",
            "Dado o texto acima, extraia informações importantes no formato abaixo:\n",
            "<CHAVE>:<VALOR>\n",
            "\n",
            "1. Nome: Alan Mathison Turing\n",
            "2. Data de nascimento: 23 de junho de 1912\n",
            "3. Data de falecimento: 7 de junho de 1954\n",
            "4. Local de nascimento: Londres\n",
            "5. Local de falecimento: Wilmslow, Cheshire\n",
            "6. Realizações: matemático, cientista da computação, lógico, criptoanalista, filósofo e biólogo teórico\n",
            "7. Contribuições para a ciência da computação teórica: formalização dos conceitos de algoritmo e computação com a máquina de Turing, considerada um modelo de um computador de uso geral.\n",
            "8. Reconhecimento: não foi totalmente reconhecido em seu país de origem durante sua vida por ser homossexual e porque grande parte de seu trabalho foi coberto pela Lei de Segredos Oficiais.\n"
          ]
        }
      ],
      "source": [
        "texto = \"Alan Mathison Turing (Londres, 23 de junho de 1912 — Wilmslow, Cheshire, 7 de junho de 1954)\"\\\n",
        "        \"foi um matemático, cientista da computação, lógico, criptoanalista, filósofo e biólogo teórico \"\\\n",
        "        \"britânico. Turing foi altamente influente no desenvolvimento da moderna ciência da computação \"\\\n",
        "        \"teórica, proporcionando uma formalização dos conceitos de algoritmo e computação com a máquina \"\\\n",
        "        \"de Turing, que pode ser considerada um modelo de um computador de uso geral. Ele é amplamente \"\\\n",
        "        \"considerado o pai da ciência da computação teórica e da inteligência artificial. Apesar dessas \"\\\n",
        "        \"realizações ele nunca foi totalmente reconhecido em seu país de origem durante sua vida por ser \"\\\n",
        "        \"homossexual e porque grande parte de seu trabalho foi coberto pela Lei de Segredos Oficiais.\"\n",
        "\n",
        "resultado = avaliarEI(texto)\n",
        "\n",
        "print(resultado.get('text'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KX7dU3GlyRr"
      },
      "source": [
        "## 5.2 - Entidade nomeada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-RNaXagl0ur"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarEN(texto):\n",
        "\n",
        "  prompt_template = \"\"\"Detecte as entidades nomeadas no texto a seguir delimitado por aspas triplas.\n",
        "Retorne apenas a resposta no formato json com spans(Um array que representa o intervalo de caracteres (índices) nos quais a entidade nomeada ocorre no texto original. O primeiro valor no array é o índice inicial(\\\"inicio\\\") e o segundo é o índice final(\\\"fim\\\")) das entidades nomeadas com os campos \\\"entidadeNomeada\\\", \\\"tipo\\\", \\\"span\\\".\n",
        "Retorne todas as entidades.\n",
        "'''{texto}'''\n",
        "\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  prompt = PromptTemplate(input_variables=[\"texto\"],\n",
        "                          template = prompt_template)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = LLMChain(llm=model_llm, prompt=prompt)\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.invoke(input={\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkprHhiNmLFi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ed01ff-56cd-4cc3-f600-dd887f1c12b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecte as entidades nomeadas no texto a seguir delimitado por aspas triplas.\n",
            "Retorne apenas a resposta no formato json \n",
            "com spans(Um array que representa o intervalo de caracteres (índices) nos quais a entidade nomeada ocorre no texto origi\n",
            "nal. O primeiro valor no array é o índice inicial(\"inicio\") e o segundo é o índice final(\"fim\")) das entidades nomeadas \n",
            "com os campos \"entidadeNomeada\", \"tipo\", \"span\".\n",
            "Retorne todas as entidades.\n",
            "'''Alan Mathison Turing (Londres, 23 de jun\n",
            "ho de 1912 — Wilmslow, Cheshire, 7 de junho de 1954)foi um matemático, cientista da computação, lógico, criptoanalista, \n",
            "filósofo e biólogo teórico britânico. Turing foi altamente influente no desenvolvimento da moderna ciência da computação\n",
            " teórica, proporcionando uma formalização dos conceitos de algoritmo e computação com a máquina de Turing, que pode ser \n",
            "considerada um modelo de um computador de uso geral. Ele é amplamente considerado o pai da ciência da computação teórica\n",
            " e da inteligência artificial. Apesar dessas realizações ele nunca foi totalmente reconhecido em seu país de origem dura\n",
            "nte sua vida por ser homossexual e porque grande parte de seu trabalho foi coberto pela Lei de Segredos Oficiais.'''\n",
            "\n",
            "Re\n",
            "sposta:\n",
            "{\n",
            "\"entidadesNomeadas\": [\n",
            "{\n",
            "\"entidadeNomeada\": \"Alan Mathison Turing\",\n",
            "\"tipo\": \"Pessoa\",\n",
            "\"span\": [10, 17]\n",
            "},\n",
            "{\n",
            "\"e\n",
            "ntidadeNomeada\": \"Londres\",\n",
            "\"tipo\": \"Lugar\",\n",
            "\"span\": [13, 15]\n",
            "},\n",
            "{\n",
            "\"entidadeNomeada\": \"Wilmslow\",\n",
            "\"tipo\": \"Lugar\",\n",
            "\"span\n",
            "\": [20, 23]\n",
            "},\n",
            "{\n",
            "\"entidadeNomeada\": \"Cheshire\",\n",
            "\"tipo\": \"Lugar\",\n",
            "\"span\": [24, 26]\n",
            "}\n",
            "]\n",
            "}\n",
            "\n",
            "Note: O array \"span\" é um array\n",
            " de números que representam o intervalo de caracteres (índices) nos quais a entidade nomeada ocorre no texto original. O\n",
            " primeiro valor no array é o índice inicial(\"inicio\") e o segundo é o índice final(\"fim\").\n"
          ]
        }
      ],
      "source": [
        "texto = \"Alan Mathison Turing (Londres, 23 de junho de 1912 — Wilmslow, Cheshire, 7 de junho de 1954)\"\\\n",
        "        \"foi um matemático, cientista da computação, lógico, criptoanalista, filósofo e biólogo teórico \"\\\n",
        "        \"britânico. Turing foi altamente influente no desenvolvimento da moderna ciência da computação \"\\\n",
        "        \"teórica, proporcionando uma formalização dos conceitos de algoritmo e computação com a máquina \"\\\n",
        "        \"de Turing, que pode ser considerada um modelo de um computador de uso geral. Ele é amplamente \"\\\n",
        "        \"considerado o pai da ciência da computação teórica e da inteligência artificial. Apesar dessas \"\\\n",
        "        \"realizações ele nunca foi totalmente reconhecido em seu país de origem durante sua vida por ser \"\\\n",
        "        \"homossexual e porque grande parte de seu trabalho foi coberto pela Lei de Segredos Oficiais.\"\n",
        "\n",
        "resultado = avaliarEN(texto)\n",
        "\n",
        "print_linhas_menores(resultado.get('text'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3rpc-_yfN3p"
      },
      "source": [
        "## 5.3 - Análise de sentimentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRYDcKB3UwBm"
      },
      "source": [
        "### 5.3.1 - Análise de sentimentos 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4ZW8PZQnxAW"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarAS1(texto):\n",
        "\n",
        "  # Cria o texto de prompt\n",
        "  prompt_template = \"\"\"Classifique os exemplos a seguir de acordo com as seguintes polaridades Positivo, Negativo e Neutro.\n",
        "EXEMPLO:\\n {texto}\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  prompt = PromptTemplate(input_variables=[\"texto\"],\n",
        "                          template = prompt_template)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = LLMChain(llm=model_llm, prompt=prompt)\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.invoke(input={\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQ4S-1saUwBn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a166ff2-31d2-40b6-ed9a-eaa09a48eb8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifique os exemplos a seguir de acordo com as seguintes polaridades Positivo, Negativo e Neutro.\n",
            "EXEMPLO:\n",
            " 1 - Minha Experiência na loja foi incrível.2 - Eu acho que podiam melhorar o produto.3 - O atendimento foi horrível!4 - Não volto mais.5 - Recomendo demais a banoffe. É uma delícia!\n",
            "\n",
            "Polaridade Positiva:\n",
            "\n",
            "* 1 - Minha Experiência na loja foi incrível.\n",
            "* 5 - Recomendo demais a banoffe. É uma delícia!\n",
            "\n",
            "Polaridade Negativa:\n",
            "\n",
            "* 2 - Eu acho que podiam melhorar o produto.\n",
            "* 4 - Não volto mais.\n",
            "\n",
            "Polaridade Neutra:\n",
            "\n",
            "* 3 - O atendimento foi horrível!\n"
          ]
        }
      ],
      "source": [
        "texto = \"1 - Minha Experiência na loja foi incrível.\"\\\n",
        "        \"2 - Eu acho que podiam melhorar o produto.\"\\\n",
        "        \"3 - O atendimento foi horrível!\"\\\n",
        "        \"4 - Não volto mais.\"\\\n",
        "        \"5 - Recomendo demais a banoffe. É uma delícia!\"\n",
        "\n",
        "resultado = avaliarAS1(texto)\n",
        "\n",
        "print(resultado.get('text'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNgeAi-MfJ-B"
      },
      "source": [
        "### 5.3.2 - Análise de sentimentos 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXF9ShhDoAFI"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarAS2(texto):\n",
        "\n",
        "#   # Cria o texto de prompt\n",
        "  prompt_template = \"\"\"DECLARAÇÕES: {texto}\n",
        "Classifique as declarações acima de acordo com as polaridades Positivo, Negativo e Neutro.\n",
        "Preserve a exata formatação do template apresentado: \\n\n",
        "###DECLARAÇÃO:<DECLARAÇÃO>\n",
        "###POLARIDADE:<POLARIDADE>.\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  prompt = PromptTemplate(input_variables=[\"texto\"],\n",
        "                          template = prompt_template)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = LLMChain(llm=model_llm, prompt=prompt)\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.invoke(input={\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2R_YBdrfJ-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd211c72-35c2-4f81-d79d-34f485741f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DECLARAÇÕES: 1 - Minha Experiência na loja foi incrível.2 - Eu acho que podiam melhorar o produto.3 - O atendimento foi horrível!4 - Não volto mais.5 - Recomendo demais a banoffe. É uma delícia!\n",
            "Classifique as declarações acima de acordo com as polaridades Positivo, Negativo e Neutro.\n",
            "Preserve a exata formatação do template apresentado: \n",
            "\n",
            "###DECLARAÇÃO:<DECLARAÇÃO>\n",
            "###POLARIDADE:<POLARIDADE>.\n",
            "\n",
            "Exemplo:\n",
            "\n",
            "###DECLARAÇÃO: Minha Experiência na loja foi incrível.\n",
            "###POLARIDADE: Positivo.\n",
            "\n",
            "###DECLARAÇÃO: Eu acho que podiam melhorar o produto.\n",
            "###POLARIDADE: Negativo.\n",
            "\n",
            "###DECLARAÇÃO: O atendimento foi horrível!\n",
            "###POLARIDADE: Negativo.\n",
            "\n",
            "###DECLARAÇÃO: Não volto mais.\n",
            "###POLARIDADE: Negativo.\n",
            "\n",
            "###DECLARAÇÃO: Recomendo demais a banoffe. É uma delícia!\n",
            "###POLARIDADE: Positivo.\n"
          ]
        }
      ],
      "source": [
        "texto = \"1 - Minha Experiência na loja foi incrível.\"\\\n",
        "        \"2 - Eu acho que podiam melhorar o produto.\"\\\n",
        "        \"3 - O atendimento foi horrível!\"\\\n",
        "        \"4 - Não volto mais.\"\\\n",
        "        \"5 - Recomendo demais a banoffe. É uma delícia!\"\n",
        "\n",
        "resultado = avaliarAS2(texto)\n",
        "\n",
        "print(resultado.get('text'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdnnZIYcCYr9"
      },
      "source": [
        "## 5.4 - Pergunta e resposta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDW7Mckg8Qj3"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "def avaliarPR(texto):\n",
        "  '''\n",
        "    Alterações no texto e tabulação impedem a geração da resposta.\n",
        "  '''\n",
        "  # Cria o texto de prompt\n",
        "  prompt_template = \"\"\"Dado o texto a seguir: {texto}\\n\n",
        "          Gere quatro questões em língua portuguesa e suas respectivas respostas utilizando apenas o template abaixo.\\n\n",
        "          Preserve a exata formatação do template apresentado: \\n\n",
        "          PERGUNTA:<PERGUNTA>\n",
        "          RESPOSTA:<RESPOSTA>\"\"\"\n",
        "\n",
        "  # Cria o prompt\n",
        "  prompt = PromptTemplate(input_variables=[\"texto\"],\n",
        "                          template = prompt_template)\n",
        "\n",
        "  # Instancia o chain\n",
        "  chain = LLMChain(llm=model_llm, prompt=prompt)\n",
        "\n",
        "  # Executa o prompt no llm\n",
        "  resultado = chain.invoke(input={\"texto\": texto})\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Alan Mathison Turing (Londres, 23 de junho de 1912 — Wilmslow, Cheshire, 7 de junho de 1954)\"\\\n",
        "        \"foi um matemático, cientista da computação, lógico, criptoanalista, filósofo e biólogo teórico \"\\\n",
        "        \"britânico. Turing foi altamente influente no desenvolvimento da moderna ciência da computação \"\\\n",
        "        \"teórica, proporcionando uma formalização dos conceitos de algoritmo e computação com a máquina \"\\\n",
        "        \"de Turing, que pode ser considerada um modelo de um computador de uso geral. Ele é amplamente \"\\\n",
        "        \"considerado o pai da ciência da computação teórica e da inteligência artificial. Apesar dessas \"\\\n",
        "        \"realizações ele nunca foi totalmente reconhecido em seu país de origem durante sua vida por ser \"\\\n",
        "        \"homossexual e porque grande parte de seu trabalho foi coberto pela Lei de Segredos Oficiais.\"\n",
        "\n",
        "resultado = avaliarPR(texto)\n",
        "\n",
        "print(resultado.get('text'))"
      ],
      "metadata": {
        "id": "qHGHQTUv72F3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6349a17-ddd4-43b1-d883-4029536f6aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dado o texto a seguir: Alan Mathison Turing (Londres, 23 de junho de 1912 — Wilmslow, Cheshire, 7 de junho de 1954)foi um matemático, cientista da computação, lógico, criptoanalista, filósofo e biólogo teórico britânico. Turing foi altamente influente no desenvolvimento da moderna ciência da computação teórica, proporcionando uma formalização dos conceitos de algoritmo e computação com a máquina de Turing, que pode ser considerada um modelo de um computador de uso geral. Ele é amplamente considerado o pai da ciência da computação teórica e da inteligência artificial. Apesar dessas realizações ele nunca foi totalmente reconhecido em seu país de origem durante sua vida por ser homossexual e porque grande parte de seu trabalho foi coberto pela Lei de Segredos Oficiais.\n",
            "\n",
            "          Gere quatro questões em língua portuguesa e suas respectivas respostas utilizando apenas o template abaixo.\n",
            "\n",
            "          Preserve a exata formatação do template apresentado: \n",
            "\n",
            "          PERGUNTA:<PERGUNTA>\n",
            "          RESPOSTA:<RESPOSTA>\n",
            "\n",
            "          FIM DA PERGUNTA\n",
            "\n",
            "Questão 1:\n",
            "PERGUNTA: Qual era o nome completo de Alan Turing?\n",
            "RESPOSTA: Alan Mathison Turing.\n",
            "\n",
            "Questão 2:\n",
            "PERGUNTA: Em que ano nasceu Alan Turing?\n",
            "RESPOSTA: Nasceu em 1912.\n",
            "\n",
            "Questão 3:\n",
            "PERGUNTA: Qual é o título do trabalho de Turing que é considerado um modelo de um computador de uso geral?\n",
            "RESPOSTA: A máquina de Turing.\n",
            "\n",
            "Questão 4:\n",
            "PERGUNTA: Por que motivo Alan Turing não foi totalmente reconhecido em seu país de origem durante sua vida?\n",
            "RESPOSTA: Ele não foi reconhecido por ser homossexual e porque grande parte de seu trabalho foi coberto pela Lei de Segredos Oficiais.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfw5EjYDgDQm"
      },
      "source": [
        "# 6 - Exemplos de padrão de pessoa (padrão persona) em prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw9f51yZkf8o"
      },
      "source": [
        "## 6.1 Um matemático"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cNZ6ykkqSYa"
      },
      "outputs": [],
      "source": [
        "def avaliarTexto(texto):\n",
        "\n",
        "  # Executa o texto no llm\n",
        "  resultado = model_llm.invoke(texto)\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jy63e1xykf8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b56b77c-183d-4417-be7d-971de2bdb794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Escreva como se fosse um professor de matemática. Me explique no idioma português a importância do teorema de pitágoras.\n",
            "\n",
            "\n",
            "O teorema de Pitágoras é um dos teoremas matemáticos mais importantes da história. Este teorema afirma que, em um triâ\n",
            "ngulo retângulo, o quadrado da hipotenusa é igual à soma dos quadrados dos catetos.\n",
            "\n",
            "Em outras palavras, se você conhece\n",
            "r a comprimento da hipotenusa e dos catetos de um triângulo retângulo, pode calcular o comprimento da hipotenusa apenas \n",
            "com a ajuda do teorema de Pitágoras. Isso é muito útil em muitas áreas da vida, como na construção de edifícios, na enge\n",
            "nharia, na física e em muitas outras.\n",
            "\n",
            "O teorema de Pitágoras foi descoberto pelo grego Pitágoras, que viveu no século V\n",
            "I a.C. Ele observou que, em um triângulo retângulo, o comprimento da hipotenusa era sempre igual à soma dos comprimentos\n",
            " dos catetos. Isso é muito interessante, pois significa que, se você conhecer o comprimento de uma das medidas de um tri\n",
            "ângulo retângulo, pode calcular o comprimento da outra medida apenas com a ajuda do teorema de Pitágoras.\n",
            "\n",
            "O teorema de \n",
            "Pitágoras é usado em muitas áreas da vida, como na construção de edifícios, na engenharia, na física e em muitas outras.\n",
            " Por exemplo, se você precisar construir um edifício com um teto retângulo, você pode usar o teorema de Pitágoras para c\n",
            "alcular o comprimento das fachadas do edifício. Isso é muito útil, pois permite que você construa o edifício de forma pr\n",
            "ecisa e segura.\n",
            "\n",
            "Além disso, o teorema de Pitágoras é usado em muitas áreas da física, como na determinação da distância\n",
            " de um objeto a uma luz ou na medida da distância de um objeto a outro objeto. Isso é muito útil, pois permite que você \n",
            "faça medições precisas e confiáveis.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "texto = 'Escreva como se fosse um professor de matemática. Me explique no idioma português a importância do teorema de pitágoras.'\n",
        "\n",
        "resultado = avaliarTexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTrJshC4gOiA"
      },
      "source": [
        "## 6.2 Um advogado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6hEVjpCqymR"
      },
      "outputs": [],
      "source": [
        "def avaliarTexto(texto):\n",
        "\n",
        "  # Executa o texto no llm\n",
        "  resultado = model_llm.invoke(texto)\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bg_VZF7dg6o5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a826c9-0996-4c5f-d1a1-594c0d4ae4c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Escreva como se fosse um advogado brasileiro especialista em direito penal.         Pontue de forma resumida as possívei\n",
            "s penas para um caso de lesão corporal leve sem contexto de violência doméstica.\n",
            "\n",
            "O advogado brasileiro especializado em\n",
            " direito penal, Sr. Neto, esclarece que a Lei nº 8.069/90 determina que a lesão corporal leve é punida com detenção de a\n",
            "té 3 anos e multa de até R$ 1.500,00. No entanto, se o caso for relatado em um contexto de violência doméstica, a pena p\n",
            "ode ser aumentada.\n",
            "\n",
            "Sr. Neto destaca que a Lei nº 11.305/06 estabelece que, em casos de violência doméstica, a pena para\n",
            " lesão corporal leve pode ser aumentada até 5 anos de detenção. Além disso, a Lei nº 12.857/11 estabelece que a violênci\n",
            "a doméstica é punida com detenção de até 8 anos, independentemente da grau da lesão corporal.\n",
            "\n",
            "Portanto, se o caso for r\n",
            "elatado em um contexto de violência doméstica, a pena para lesão corporal leve pode ser aumentada de 3 anos até 5 anos d\n",
            "e detenção, ou até 8 anos de detenção, dependendo da grau da lesão corporal. É importante lembrar que essas penas são ap\n",
            "enas uma possível interpretação do direito penal brasileiro e que é recomendável consultar um profissional de direito pa\n",
            "ra obter orientação específica em cada caso.\n"
          ]
        }
      ],
      "source": [
        "texto = \"Escreva como se fosse um advogado brasileiro especialista em direito penal. \\\n",
        "        Pontue de forma resumida as possíveis penas para um caso de lesão corporal leve sem contexto de violência doméstica.\"\n",
        "\n",
        "resultado = avaliarTexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO5Ij9_FZTqR"
      },
      "source": [
        "## 6.3 Um astrofísico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhvOsGiVZTqZ"
      },
      "outputs": [],
      "source": [
        "def avaliarTexto(texto):\n",
        "\n",
        "  # Executa o texto no llm\n",
        "  resultado = model_llm.invoke(texto)\n",
        "\n",
        "  return resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuvvmTx7AqSN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e98ef818-a47c-41cb-c3cc-4ccdcb843ed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Escreva em português como se fosse um astrofísico. Me explique por que o universo está expandindo.\n",
            "\n",
            "🚀 Olá! 🌟 Como um ast\n",
            "rofísico, eu posso explicar por que o universo está expandindo. 💫\n",
            "\n",
            "🔍 A expansão do universo é um fenômeno que ocorre dev\n",
            "ido à energia escura, que é uma propriedade da matéria e do espaço. Essa energia escura é uma força que actua em todas a\n",
            "s partes do universo e faz com que as estrelas, galáxias e outros corpos celestes se afastem uns dos outros. 🔥\n",
            "\n",
            "🔬 A expa\n",
            "nsão do universo começou em um momento em que a temperatura do universo era muito alta, cerca de 13,8 bilhões de anos at\n",
            "rás. Desde então, a temperatura do universo está diminuindo e o universo está expandindo-se. 🌊\n",
            "\n",
            "🔭 A expansão do universo\n",
            " é medida por meio da distância entre as galáxias. A distância entre as galáxias é medida em megaparsecs (Mpc), que é um\n",
            "a unidade de comprimento utilizada em astronomia. A distância entre as galáxias é maior que a distância entre as estrela\n",
            "s, e maior ainda que a distância entre as planetas. 🌠\n",
            "\n",
            "🔬 A expansão do universo também é medida por meio da radiação cós\n",
            "mica de fundo (CMB). A CMB é a radiação eletrônica que venceu a reionização do universo, cerca de 380.000 anos após o Bi\n",
            "g Bang. A CMB fornece informações valiosas sobre a composição e a história do universo. 🔍\n",
            "\n",
            "💭 Então, a expansão do univer\n",
            "so é um fenômeno natural que ocorre devido à energia escura. A distância entre as galáxias e a radiação cósmica de fundo\n",
            " são as principais medidas da expansão do universo. �������\n"
          ]
        }
      ],
      "source": [
        "texto = \"Escreva em português como se fosse um astrofísico. Me explique por que o universo está expandindo.\"\n",
        "\n",
        "resultado = avaliarTexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aN8SgzyAfc_"
      },
      "source": [
        "Em algumas execuções o modelo responde em inglês."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRoS9dFWZTqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbe787d5-d9db-4fc1-d150-fd80b5b0a364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Escreva como se fosse um astrofísico. Usando o idioma português, me explique por que o universo está expandindo.\n",
            "\n",
            "Eu sou\n",
            " um astrofísico, e hoje quero compartilhar com vocês um dos maiores mistérios da ciência: o fenômeno da expansão do univ\n",
            "erso.\n",
            "\n",
            "A ideia de que o universo está expandindo pode parecer estranha, mas a evidência científica é muito clara. Ao lon\n",
            "go dos últimos 13 bilhões de anos, o universo tem estado expandindo-se a uma taxa constante, e isso é comprovado por obs\n",
            "ervações em todo o espectro da luz, desde a luz visível até a luz de raios-X.\n",
            "\n",
            "A expansão do universo pode ser entendida\n",
            " como um processo de expansão de uma buraco de tamanho constante, que começa no Big Bang e continua até os dias atuais. \n",
            "A taxa de expansão é uma função do tempo, e a distância entre as estrelas e galáxias aumenta a medida que o universo se \n",
            "expande.\n",
            "\n",
            "A explicação para essa expansão é complexa e envolve a teoria da relatividade geral de Albert Einstein. Essa t\n",
            "eoria sugere que a gravidade é a força que governa o universo, e que a expansão do universo é causada pela energia escur\n",
            "a, um tipo de energia que permeia o universo e faz com que as estrelas e galáxias se afastem uns das outras.\n",
            "\n",
            "A energia \n",
            "escura é uma força que é presente em todo o universo e é responsável pela expansão do mesmo. A quantidade de energia esc\n",
            "ura presente no universo é extremamente grande, de modo que a expansão do universo é uma consequência direta da energia \n",
            "escura.\n",
            "\n",
            "A expansão do universo tem importantes implicações para a nossa compreensão do universo. Por exemplo, a distânc\n",
            "ia entre as galáxias aumenta a medida que o universo se expande, o que significa que as galáxias que eram próximas uma v\n",
            "ez agora estão muito longe. Além disso, a expansão do\n"
          ]
        }
      ],
      "source": [
        "texto = 'Escreva como se fosse um astrofísico. Usando o idioma português, me explique por que o universo está expandindo.'\n",
        "\n",
        "resultado = avaliarTexto(texto)\n",
        "\n",
        "print_linhas_menores(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWxaKJ1o3tWG"
      },
      "source": [
        "# 6 - Padrão de Verificação Cognitiva\n",
        "\n",
        "Divide perguntas complexas em subperguntas menores e gerenciáveis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNV4TEFZ3zBk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38c38de5-0eca-4422-b233-1367f901991b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Em um caso de agressão corporal o indivíduo agredido sofreu sequelas permanentes e encontra-se impossibilitado de trabal\n",
            "har. O agressor poderá ser sentenciado à prisão e ao pagamento de indenização vitalícia? Considere a legislação brasilei\n",
            "ra.\n",
            "\n",
            "A respeito da legislação brasileira, é importante destacar que o art. 127, inciso III, do Código de Processo Penal \n",
            "(CPP) estabelece que o agressor pode ser punido com prisão, desde que a agressão tenha causado lesão corporal grave. A l\n",
            "esão corporal grave é definida no art. 29, II, do Código de Medicina Legal, como qualquer lesão corporal que cause alter\n",
            "ação na integridade física do corpo, independentemente de sua gravidade.\n",
            "\n",
            "Além disso, o art. 130, I, do CPP, estabelece \n",
            "que o agressor pode ser punido com indenização vitalícia, ou seja, uma indenização financeira paga vitalicamente, para o\n",
            " benefício do vítima, em caso de agressão corporal que cause lesão corporal grave.\n",
            "\n",
            "Em relação à sequela permanente, o a\n",
            "rt. 128, I, do CPP, estabelece que o agressor pode ser punido com prisão, desde que a agressão tenha causado sequela per\n",
            "manente. A sequela permanente é definida no art. 29, III, do Código de Medicina Legal, como qualquer sequela que persist\n",
            "a após o término do processo penal.\n",
            "\n",
            "Em resumo, de acordo com a legislação brasileira, o agressor pode ser punido com pr\n",
            "isão e indenização vitalícia em caso de agressão corporal que cause lesão corporal grave e sequela permanente.\n"
          ]
        }
      ],
      "source": [
        "texto = 'Em um caso de agressão corporal o indivíduo agredido sofreu sequelas '\\\n",
        "        'permanentes e encontra-se impossibilitado de trabalhar. O agressor poderá ser sentenciado ' \\\n",
        "        'à prisão e ao pagamento de indenização vitalícia? Considere a legislação brasileira.'\n",
        "\n",
        "resultado = model_llm.invoke(texto)\n",
        "\n",
        "print_linhas_menores(resultado, 120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M2DIo5e8uU_"
      },
      "source": [
        "# 7 - Pensamento em cadeia(Chain-of-Thought)\n",
        "\n",
        "Uma cadeia de prompts interconectados pode estimular o raciocínio nos modelos de linguagem.\n",
        "\n",
        "FONTE: https://arxiv.org/pdf/2201.11903.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCzzlI-FAxCX"
      },
      "source": [
        "Aumenta a quantidade de caracteres de saída do pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxhzacFzAX7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2b3eef8-5c33-4dc3-def3-e0d2d46e63f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'OptimizedModule' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'JambaForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'OlmoForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
          ]
        }
      ],
      "source": [
        "# Import das bibliotecas\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import pipeline\n",
        "\n",
        "# Configura o pipeline\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    trust_remote_code=True,\n",
        "    max_length=1024\n",
        ")\n",
        "\n",
        "# Carrega o pipeline\n",
        "# https://python.langchain.com/docs/integrations/llms/huggingface_pipelines\n",
        "model_llm = HuggingFacePipeline(\n",
        "    pipeline=pipe,\n",
        "    model_kwargs={\"temperature\": 0.1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nygjlPmZ_HL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b25c162-906a-44bf-95d1-225c13b42e83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: Roger tem 5 bolas de tênis. Ele compra mais 2 pacotes de bolas de tênis.Cada pacote tem 2 bolas de tênis. Quantas bol\n",
            "as de tênis Roger tem agora?A: Roger tinha 5 bolas de tênis. 2 pacotes com 3 bolas de tênis em cadaum dá um total de 6 b\n",
            "olas de tênis. 5 + 6 = 11. A resposta é 11.\n",
            "Q: A cafeteria tinha 23 maçãs. Se eles usaram 20 delas para fazer umatorta e\n",
            " depois compraram mais 6 maçãs, quantas maçãs tem na cafeteria?A: A cafeteria começou com 23 maçãs. Usaram 20 delas para\n",
            " fazer um torta, então tem 3 maçãs restantes. Depois compraram mais 6 maçãs, portanto, a resposta é 9 (3 + 6).\n",
            "\n",
            "Essas sã\n",
            "o algumas das perguntas e respostas comuns para o teste de Q&A do curso de Programação para Crianças. É importante lembr\n",
            "ar que o objetivo do teste é avaliar a compreensão dos conceitos básicos de programação e não a habilidade de resolver p\n",
            "roblemas complexos.\n"
          ]
        }
      ],
      "source": [
        "texto = 'Q: Roger tem 5 bolas de tênis. Ele compra mais 2 pacotes de bolas de tênis.'\\\n",
        "        'Cada pacote tem 2 bolas de tênis. Quantas bolas de tênis Roger tem agora?'\\\n",
        "        'A: Roger tinha 5 bolas de tênis. 2 pacotes com 3 bolas de tênis em cada'\\\n",
        "        'um dá um total de 6 bolas de tênis. 5 + 6 = 11. A resposta é 11.'\\\n",
        "        '\\nQ: A cafeteria tinha 23 maçãs. Se eles usaram 20 delas para fazer uma'\\\n",
        "        'torta e depois compraram mais 6 maçãs, quantas maçãs tem na cafeteria?'\n",
        "\n",
        "resultado = model_llm.invoke(texto)\n",
        "\n",
        "print_linhas_menores(resultado, 120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttOpEPEZGzgy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d97e63-2784-4ac1-adec-34b2586d62da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: Roger tem 5 bolas de tênis. Ele compra mais 2 pacotes de bolas de tênis.Cada pacote tem 2 bolas de tênis. Quantas bol\n",
            "as de tênis Roger tem agora?A: Roger tinha 5 bolas de tênis. 2 pacotes com 3 bolas de tênis em cadaum dá um total de 6 b\n",
            "olas de tênis. 5 + 6 = 11. A resposta é 11.\n",
            "Q: A cafeteria tinha 23 maçãs. Se eles usaram 20 delas para fazer umatorta e\n",
            " depois compraram mais 6 maçãs, quantas maçãs tem na cafeteria?A: A cafeteria teve 23 maçãs originalmente. Eles usaram 2\n",
            "0 delas para fazer um torta, o que deixou 3 maçãs. Em seguida, eles compraram 6 maçãs, o que significa que agora a cafet\n",
            "eria tem 3 + 6 = 9 maçãs. A resposta é 9.\n",
            "Q: Maria tem 15 bolas de tênis. Ela vende 3 delas e em seguida compra mais 2 b\n",
            "olas de tênis.Quantas bolas de tênis tem Maria agora?A: Maria teve 15 bolas de tênis originalmente. Ela vendeu 3 delas, \n",
            "o que deixou 15 - 3 = 12 bolas de tênis. Em seguida, ela comprou 2 novas bolas de tênis, o que significa que agora Maria\n",
            " tem 12 + 2 = 14 bolas de tênis. A resposta é 14.\n",
            "Q: O supermercado tem 25 pacotes de leite. Cada pacote tem 4 litros de\n",
            " leite. Quantos litros de leite tem o supermercado em total?A: O supermercado tem 25 pacotes de leite. Cada pacote tem 4\n",
            " litros de leite, o que significa que o supermercado tem 25 x 4 = 100 litros de leite em total. A resposta é 100.\n",
            "\n",
            "Essas\n",
            " são algumas perguntas e respostas comuns para um jogo de adivinhação de quantos. É importante lembrar que a resposta po\n",
            "de ser uma quantidade, um número ou uma medida, e que é preciso usar a lógica e a matemática para resolver as perguntas \n",
            "corretamente.\n"
          ]
        }
      ],
      "source": [
        "texto = 'Q: Roger tem 5 bolas de tênis. Ele compra mais 2 pacotes de bolas de tênis.'\\\n",
        "        'Cada pacote tem 2 bolas de tênis. Quantas bolas de tênis Roger tem agora?'\\\n",
        "        'A: Roger tinha 5 bolas de tênis. 2 pacotes com 3 bolas de tênis em cada'\\\n",
        "        'um dá um total de 6 bolas de tênis. 5 + 6 = 11. A resposta é 11.'\\\n",
        "        '\\nQ: A cafeteria tinha 23 maçãs. Se eles usaram 20 delas para fazer uma'\\\n",
        "        'torta e depois compraram mais 6 maçãs, quantas maçãs tem na cafeteria?'\n",
        "\n",
        "resultado = model_llm.invoke(texto, model_kwargs={\"temperature\": 0.1})\n",
        "\n",
        "print_linhas_menores(resultado, 120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2LRlh82_L9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d5ab7e-4914-4c7c-f2e3-291b6223e6c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: Os números ímpares no grupo a seguir quando somados resultam em umnúmero par: 4, 8, 9, 15, 12, 2, 1.\n",
            "A: Somar todos o\n",
            "s números ímpares (9, 15, 1) resulta em 25.25 é um número ímpar. Portanto a assertiva anterior é Falsa.\n",
            "Q: Os números ím\n",
            "pares no grupo a seguir quando somados resultamem um número par: 15, 32, 5, 13, 82, 7, 1.\n",
            "A: Somar todos os números ímpa\n",
            "res (5, 13, 7) resulta em 35.35 é um número par. Portanto a assertiva anterior é Falsa.\n",
            "\n",
            "Ao analisar as respostas, podem\n",
            "os ver que a assertiva \"Os números ímpares no grupo a seguir quando somados resultam em um número par\" é falsa, pois exi\n",
            "stem casos em que os números ímpares somados resultam em um número par.\n"
          ]
        }
      ],
      "source": [
        "texto = 'Q: Os números ímpares no grupo a seguir quando somados resultam em um' \\\n",
        "        'número par: 4, 8, 9, 15, 12, 2, 1.'\\\n",
        "        '\\nA: Somar todos os números ímpares (9, 15, 1) resulta em 25.'\\\n",
        "        '25 é um número ímpar. Portanto a assertiva anterior é Falsa.'\\\n",
        "        '\\nQ: Os números ímpares no grupo a seguir quando somados resultam'\\\n",
        "        'em um número par: 15, 32, 5, 13, 82, 7, 1.'\n",
        "\n",
        "resultado = model_llm.invoke(texto)\n",
        "\n",
        "print_linhas_menores(resultado, 120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGkSD1iS3E3N"
      },
      "source": [
        "# 8 - Refinamento de perguntas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkZohUZj3GxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bdefaaf-11c4-4fae-db07-d118f107aef6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CHATGPT:  The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Sempre que eu fizer uma pergunta relacionada a computação, sugira uma pergunta mais refinada considerando as especificidades de estrutura de dados. Todo o texto deve ser escrito usando o idioma português brasileiro. Pergunte se eu gostaria de utilizar a pergunta sugerida.\n",
            "AI: Claro! Eu adoraria ajudá-lo com suas perguntas sobre computação! 🤖👨‍💻\n",
            "\n",
            "Human: Ótimo! Então, você sabe se existem algoritmos que podem detectar se uma imagem é de uma pessoa ou de um animal?\n",
            "AI: Ah, um tema interessante! 🐶🐱 Yes, there are algorithms that can detect whether an image is of a person or an animal. In fact, there are several approaches to this problem, and the choice of algorithm depends on the specific requirements and characteristics of the image.\n",
            "\n",
            "For example, one popular approach is to use a deep learning model called a convolutional neural network (CNN). These models are particularly effective at image classification tasks, and they can be trained on large datasets of labeled images to learn the patterns and features that distinguish between different types of images.\n",
            "\n",
            "Another approach is to use a technique called object detection, which involves identifying and locating specific objects within an image. This can be useful when the image contains multiple objects, such as a person and an animal, and you want to detect and classify each object separately.\n",
            "\n",
            "However, it's important to note that these algorithms are not perfect, and there may be cases where they can't accurately detect the type of image. For example, if the image is blurry or has a low resolution, the algorithm may struggle to make an accurate classification.\n",
            "\n",
            "So, to answer your question, yes, there are algorithms that can detect whether an image is of a person or an animal, but the specific approach and accuracy will depend on the details of the image and the algorithm used. Does that help? 😊\n",
            "USER: sair\n"
          ]
        }
      ],
      "source": [
        "# Importa das bibliotecas\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Apaga variável input existente\n",
        "try:\n",
        "    del input\n",
        "except NameError:\n",
        "    print(\"input não existe\")\n",
        "\n",
        "# Instancia o objeto de conversação\n",
        "conversation = ConversationChain(\n",
        "    llm=model_llm,\n",
        "    memory=ConversationBufferMemory()\n",
        ")\n",
        "\n",
        "texto = 'Sempre que eu fizer uma pergunta relacionada a computação, '\\\n",
        "        'sugira uma pergunta mais refinada considerando as especificidades de '\\\n",
        "        'estrutura de dados. Todo o texto deve ser escrito usando o idioma português brasileiro. '\\\n",
        "        'Pergunte se eu gostaria de utilizar a pergunta sugerida.'\n",
        "\n",
        "while True:\n",
        "  resposta = conversation.invoke(input=texto)\n",
        "  print(\"CHATGPT: \", resposta.get('response'))\n",
        "\n",
        "  texto = input(\"USER: \")\n",
        "  if texto.lower() == 'sair':\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuClass": "premium",
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "21d072e029f741f8924386dc117b0698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e85d39a6ae4d401389c447f9e9e720a2",
              "IPY_MODEL_1532a6765aad441a97a37e1f61a1fb0b",
              "IPY_MODEL_120227e3a4164d5c9d54562d0e95086c"
            ],
            "layout": "IPY_MODEL_1e1af129a7c4401abd5aeccbeae0e2a4"
          }
        },
        "e85d39a6ae4d401389c447f9e9e720a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57e1c19033a74badadf9fa9ff2d899f7",
            "placeholder": "​",
            "style": "IPY_MODEL_33fbce20a5ba49039052cf20d013238d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1532a6765aad441a97a37e1f61a1fb0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb54779e098d4dba9d74fa325eb949fa",
            "max": 1618,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a1374d61a9a400fb1ae637763c0c1e1",
            "value": 1618
          }
        },
        "120227e3a4164d5c9d54562d0e95086c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b79f4316e39b4dd6b424f02b48094fcb",
            "placeholder": "​",
            "style": "IPY_MODEL_11620c1357b144aea2139e023cbab147",
            "value": " 1.62k/1.62k [00:00&lt;00:00, 74.3kB/s]"
          }
        },
        "1e1af129a7c4401abd5aeccbeae0e2a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57e1c19033a74badadf9fa9ff2d899f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33fbce20a5ba49039052cf20d013238d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb54779e098d4dba9d74fa325eb949fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a1374d61a9a400fb1ae637763c0c1e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b79f4316e39b4dd6b424f02b48094fcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11620c1357b144aea2139e023cbab147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d5af3edf3034bdbb08948c8d55e6b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76ab48ae5e4946b8aac24786dda8af56",
              "IPY_MODEL_9f55a673972740a98dc09ac600be5d68",
              "IPY_MODEL_8ec59f0fcc81407bb6af298b5ac21730"
            ],
            "layout": "IPY_MODEL_4ee24757394540cab53bd79675e0f7e8"
          }
        },
        "76ab48ae5e4946b8aac24786dda8af56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22391979a5e346b5a1c302835407f92c",
            "placeholder": "​",
            "style": "IPY_MODEL_da3313cdd23649399f434cc8b188b60e",
            "value": "tokenizer.model: 100%"
          }
        },
        "9f55a673972740a98dc09ac600be5d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0913cc28c894f91a87d4cee34a1e3e2",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad5714b6a2714c0bb190f26d1e007dfd",
            "value": 499723
          }
        },
        "8ec59f0fcc81407bb6af298b5ac21730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a8cee0e1d344ab2903b74d3ea1a7e41",
            "placeholder": "​",
            "style": "IPY_MODEL_a670a9ada8b140dea5237f338f0085e0",
            "value": " 500k/500k [00:00&lt;00:00, 19.7MB/s]"
          }
        },
        "4ee24757394540cab53bd79675e0f7e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22391979a5e346b5a1c302835407f92c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da3313cdd23649399f434cc8b188b60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0913cc28c894f91a87d4cee34a1e3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad5714b6a2714c0bb190f26d1e007dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a8cee0e1d344ab2903b74d3ea1a7e41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a670a9ada8b140dea5237f338f0085e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c38c85cd517d4dd799863201a8a568d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38b9d594146d4a4eb70df039a5e1a4ec",
              "IPY_MODEL_484137fc476645c3a0a0fa8dc52ece80",
              "IPY_MODEL_ade136a160704664bae77e1fe1675482"
            ],
            "layout": "IPY_MODEL_75c31410d77a4a4ca6e29bb7562d7327"
          }
        },
        "38b9d594146d4a4eb70df039a5e1a4ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03f4c7331a1a4176b99ee322bcc5bb63",
            "placeholder": "​",
            "style": "IPY_MODEL_a1ee6c16861b406c8b32fdddb411740f",
            "value": "tokenizer.json: 100%"
          }
        },
        "484137fc476645c3a0a0fa8dc52ece80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e578eecd0cb5436184d19db998ddc989",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f94460300ee94240b192c41cc4681a50",
            "value": 1842767
          }
        },
        "ade136a160704664bae77e1fe1675482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_939074156fa0459b8834aa9aea2c5c63",
            "placeholder": "​",
            "style": "IPY_MODEL_650ab0f1abf847de8c77c6c49789b2de",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 3.82MB/s]"
          }
        },
        "75c31410d77a4a4ca6e29bb7562d7327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03f4c7331a1a4176b99ee322bcc5bb63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1ee6c16861b406c8b32fdddb411740f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e578eecd0cb5436184d19db998ddc989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f94460300ee94240b192c41cc4681a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "939074156fa0459b8834aa9aea2c5c63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "650ab0f1abf847de8c77c6c49789b2de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b117bb2aa084b69978b4d1f3eea068d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e7776766e754b02bfe2efe50ad13a64",
              "IPY_MODEL_762ae65b750646849691accf6b305b7b",
              "IPY_MODEL_049fffd112f8412fbacab7247987f870"
            ],
            "layout": "IPY_MODEL_b0a32de1b9f145509967a37aaee341d7"
          }
        },
        "3e7776766e754b02bfe2efe50ad13a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3abf98e538f44f0088e82434a08d0a25",
            "placeholder": "​",
            "style": "IPY_MODEL_ffc277fd73be4cca9535d1f86dc874a3",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "762ae65b750646849691accf6b305b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6840325304f414081a8d48bb6c9769c",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_252cd15bae0b4582b1a12989badf2b75",
            "value": 414
          }
        },
        "049fffd112f8412fbacab7247987f870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb94fe5a13d54485bb5177c0c2c2d0e4",
            "placeholder": "​",
            "style": "IPY_MODEL_e1e5b8e35d824a76af114a1e47aa7d3e",
            "value": " 414/414 [00:00&lt;00:00, 8.86kB/s]"
          }
        },
        "b0a32de1b9f145509967a37aaee341d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3abf98e538f44f0088e82434a08d0a25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffc277fd73be4cca9535d1f86dc874a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6840325304f414081a8d48bb6c9769c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "252cd15bae0b4582b1a12989badf2b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb94fe5a13d54485bb5177c0c2c2d0e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1e5b8e35d824a76af114a1e47aa7d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43fbedfdd0104fa0bd8b809e3e9be296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5af177c9f68448448f8c36427084385c",
              "IPY_MODEL_1ee2b64e90f54d1bb7d38e480e81c743",
              "IPY_MODEL_b90c28b165074241a5f8f64b27fb0ba8"
            ],
            "layout": "IPY_MODEL_0ce11403c63e4093abac84ef55938293"
          }
        },
        "5af177c9f68448448f8c36427084385c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58702fffdfa64efcb1fd21b130dc5a06",
            "placeholder": "​",
            "style": "IPY_MODEL_5d5338d429d64fb8b8fa724da5fe59a9",
            "value": "config.json: 100%"
          }
        },
        "1ee2b64e90f54d1bb7d38e480e81c743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d7aa498c0974f8e81894b78fe469f43",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1b5af67c00c4853825ff27aa0ad6fc8",
            "value": 614
          }
        },
        "b90c28b165074241a5f8f64b27fb0ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8bbbcf9f774434fb710adebdf3d9dc5",
            "placeholder": "​",
            "style": "IPY_MODEL_5dd80e70980e4f47ac5a0e90c90ed598",
            "value": " 614/614 [00:00&lt;00:00, 11.4kB/s]"
          }
        },
        "0ce11403c63e4093abac84ef55938293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58702fffdfa64efcb1fd21b130dc5a06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d5338d429d64fb8b8fa724da5fe59a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d7aa498c0974f8e81894b78fe469f43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1b5af67c00c4853825ff27aa0ad6fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8bbbcf9f774434fb710adebdf3d9dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dd80e70980e4f47ac5a0e90c90ed598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c16a28806ad4088ad497a5b9a232ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4aa4c1202a864d38919ccc20e816213f",
              "IPY_MODEL_279e524569a64f3693131df12db43849",
              "IPY_MODEL_4b4c47a15f4c471fa918c60354d78759"
            ],
            "layout": "IPY_MODEL_60695efe6a3d4145877213225de1312f"
          }
        },
        "4aa4c1202a864d38919ccc20e816213f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c3f9ffa853046b0828b88db1ffe673a",
            "placeholder": "​",
            "style": "IPY_MODEL_d6888a26d7e348fab7bc284d82e46372",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "279e524569a64f3693131df12db43849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ed1522f17c540208d8fb00011abbfa4",
            "max": 26788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99fac7c968b146428c6d7892d22f2bd6",
            "value": 26788
          }
        },
        "4b4c47a15f4c471fa918c60354d78759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2008bf056b84715ab9c2d1db214db6b",
            "placeholder": "​",
            "style": "IPY_MODEL_fa5c814b0d0949939eb2705a577ef207",
            "value": " 26.8k/26.8k [00:00&lt;00:00, 527kB/s]"
          }
        },
        "60695efe6a3d4145877213225de1312f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c3f9ffa853046b0828b88db1ffe673a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6888a26d7e348fab7bc284d82e46372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ed1522f17c540208d8fb00011abbfa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99fac7c968b146428c6d7892d22f2bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2008bf056b84715ab9c2d1db214db6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa5c814b0d0949939eb2705a577ef207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b21adb73a7b4af2babe0d229af55abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_787ad93a273d44bda844ac185ed64c33",
              "IPY_MODEL_a5f849a733c6493f9795dcff3e8d38e5",
              "IPY_MODEL_0111511dfb6d4682acb4270cf1e293ae"
            ],
            "layout": "IPY_MODEL_02153c1d14734c9897f57bd3540bc0cc"
          }
        },
        "787ad93a273d44bda844ac185ed64c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e413f2bb7554b92a0462fae443a3809",
            "placeholder": "​",
            "style": "IPY_MODEL_5a608ca8198e41ccb060ec13ce8f0d28",
            "value": "Downloading shards: 100%"
          }
        },
        "a5f849a733c6493f9795dcff3e8d38e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1c0a7c5b66041c2a9a47636065e130e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0319d13dc084a3dabe2409b8fef2c0a",
            "value": 2
          }
        },
        "0111511dfb6d4682acb4270cf1e293ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09bbf99815514948818179c1c92fda34",
            "placeholder": "​",
            "style": "IPY_MODEL_64074fca3b364c86bb4e7a0f539c952b",
            "value": " 2/2 [01:41&lt;00:00, 44.93s/it]"
          }
        },
        "02153c1d14734c9897f57bd3540bc0cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e413f2bb7554b92a0462fae443a3809": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a608ca8198e41ccb060ec13ce8f0d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1c0a7c5b66041c2a9a47636065e130e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0319d13dc084a3dabe2409b8fef2c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09bbf99815514948818179c1c92fda34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64074fca3b364c86bb4e7a0f539c952b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e57daad4217242b19b4fb8922470c942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ee96042dfe449699885119eb861d8af",
              "IPY_MODEL_0bce14bd3cd94e23b112d331871b65e4",
              "IPY_MODEL_4ff80581ed524d539057ef1af609fce9"
            ],
            "layout": "IPY_MODEL_d557909aea3d49038a505b966c75419e"
          }
        },
        "1ee96042dfe449699885119eb861d8af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa8aa80f48654c82b37c5ab62bec35ab",
            "placeholder": "​",
            "style": "IPY_MODEL_9f36a9a5720d4dae9e6e7a9d7e353c3c",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "0bce14bd3cd94e23b112d331871b65e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d60d7942e47c46f68b4169d3c08dddf0",
            "max": 9976576152,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a60e3d7aef304e5d8dac372ffb0dfb68",
            "value": 9976576152
          }
        },
        "4ff80581ed524d539057ef1af609fce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d007edb5ae94801a4c5387867789ab6",
            "placeholder": "​",
            "style": "IPY_MODEL_3009c92093334d48b26537ea46ad6596",
            "value": " 9.98G/9.98G [01:22&lt;00:00, 185MB/s]"
          }
        },
        "d557909aea3d49038a505b966c75419e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa8aa80f48654c82b37c5ab62bec35ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f36a9a5720d4dae9e6e7a9d7e353c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d60d7942e47c46f68b4169d3c08dddf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a60e3d7aef304e5d8dac372ffb0dfb68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d007edb5ae94801a4c5387867789ab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3009c92093334d48b26537ea46ad6596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91cb92fdd39e4dc98b2b428c960a04d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2ba398885c146799be1d18988156db1",
              "IPY_MODEL_dc4de582cc004b6ea6be713cfb239899",
              "IPY_MODEL_3ba95abbd8ec41639ef12320ed08a53d"
            ],
            "layout": "IPY_MODEL_94da824f5bfb468cb515cb345462bc0d"
          }
        },
        "d2ba398885c146799be1d18988156db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f727daf5a9a9484f8758323ddd1f4c1e",
            "placeholder": "​",
            "style": "IPY_MODEL_a3df1a2269e74318b775d5b5282f5222",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "dc4de582cc004b6ea6be713cfb239899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd6e0986a26a4d8784cf31088d58d427",
            "max": 3500296424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_925376d4a0324bf7ab1585b3ac54622d",
            "value": 3500296424
          }
        },
        "3ba95abbd8ec41639ef12320ed08a53d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6e15e49bad04c369357eaff53bab230",
            "placeholder": "​",
            "style": "IPY_MODEL_6edee10792af418a892e29ffd5579813",
            "value": " 3.50G/3.50G [00:18&lt;00:00, 235MB/s]"
          }
        },
        "94da824f5bfb468cb515cb345462bc0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f727daf5a9a9484f8758323ddd1f4c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3df1a2269e74318b775d5b5282f5222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd6e0986a26a4d8784cf31088d58d427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "925376d4a0324bf7ab1585b3ac54622d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6e15e49bad04c369357eaff53bab230": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6edee10792af418a892e29ffd5579813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23f6cca731574185803246f1b6926cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a69e0bec9098408c9347789b804dae0a",
              "IPY_MODEL_af1990843fbb4cf9a8bbcfcd634547ea",
              "IPY_MODEL_dcd907bf6dfe4fd3937e1b40a1779185"
            ],
            "layout": "IPY_MODEL_ec2b9645008343bf8b63c547ef430ed5"
          }
        },
        "a69e0bec9098408c9347789b804dae0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ddf97f1d17f4e36a24ab09f81b24c80",
            "placeholder": "​",
            "style": "IPY_MODEL_eee134c80f2d452f983fc3bb0c46e9d9",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "af1990843fbb4cf9a8bbcfcd634547ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb9f2057a7b343c284a4c8f57b185657",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3ff83c2dc1245679a36f13760d713c7",
            "value": 2
          }
        },
        "dcd907bf6dfe4fd3937e1b40a1779185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdf6fed73aba440db14a68c4ba2e8cf6",
            "placeholder": "​",
            "style": "IPY_MODEL_76af1daa6be44615853a31e6a74f075e",
            "value": " 2/2 [00:54&lt;00:00, 24.91s/it]"
          }
        },
        "ec2b9645008343bf8b63c547ef430ed5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ddf97f1d17f4e36a24ab09f81b24c80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eee134c80f2d452f983fc3bb0c46e9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb9f2057a7b343c284a4c8f57b185657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3ff83c2dc1245679a36f13760d713c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdf6fed73aba440db14a68c4ba2e8cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76af1daa6be44615853a31e6a74f075e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb3d36a789bc43db802d543457d60604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6a1c2dadcaa4c2282b67f456e985089",
              "IPY_MODEL_7ad11ade593d407aafccfc3d671d8ec1",
              "IPY_MODEL_98696420d3744dbe98289f54c8627327"
            ],
            "layout": "IPY_MODEL_e07c634aee4f4870954d0009b2c99efa"
          }
        },
        "a6a1c2dadcaa4c2282b67f456e985089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df01d5bac5284343848799c7bcf8f0e9",
            "placeholder": "​",
            "style": "IPY_MODEL_c1bddfe856f847ddb56906cd478c53ad",
            "value": "generation_config.json: 100%"
          }
        },
        "7ad11ade593d407aafccfc3d671d8ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ba18b2e29e14b5dbf7bcd018ece28cd",
            "max": 188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f41b10b3b3e4310a95fc15257d638e1",
            "value": 188
          }
        },
        "98696420d3744dbe98289f54c8627327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82e5a1a4bc8d421e94566147cf947daf",
            "placeholder": "​",
            "style": "IPY_MODEL_f7bb9a7de9a743d9a176ad55d1384f58",
            "value": " 188/188 [00:00&lt;00:00, 13.4kB/s]"
          }
        },
        "e07c634aee4f4870954d0009b2c99efa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df01d5bac5284343848799c7bcf8f0e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1bddfe856f847ddb56906cd478c53ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ba18b2e29e14b5dbf7bcd018ece28cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f41b10b3b3e4310a95fc15257d638e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82e5a1a4bc8d421e94566147cf947daf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7bb9a7de9a743d9a176ad55d1384f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}